{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 다대일 RNN Modeling Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu와 cuda 중 다음 기기로 학습함: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1d0602546d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchtext import data, datasets\n",
    "import random\n",
    "from torchtext.data import TabularDataset\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(\"cpu와 cuda 중 다음 기기로 학습함:\", DEVICE)\n",
    "\n",
    "SEED = 5\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-1. Review Data 수집 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('IMDb_Reviews.csv', <http.client.HTTPMessage at 0x28a2c456d08>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/LawrenceDuan/IMDb-Review-Analysis/master/IMDb_Reviews.csv\", filename=\"IMDb_Reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My family and I normally do not watch local mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Believe it or not, this was at one time the wo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>After some internet surfing, I found the \"Home...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One of the most unheralded great works of anim...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It was the Sixties, and anyone with long hair ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  My family and I normally do not watch local mo...          1\n",
       "1  Believe it or not, this was at one time the wo...          0\n",
       "2  After some internet surfing, I found the \"Home...          0\n",
       "3  One of the most unheralded great works of anim...          1\n",
       "4  It was the Sixties, and anyone with long hair ...          0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('IMDb_Reviews.csv', encoding='latin1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 개수 : 50000\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플의 개수 : {}'.format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My family and I normally do not watch local mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Believe it or not, this was at one time the wo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It would be unfair to the actors to condemn th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One of the most unheralded great works of anim...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It was the Sixties, and anyone with long hair ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  My family and I normally do not watch local mo...          1\n",
       "1  Believe it or not, this was at one time the wo...          0\n",
       "2  It would be unfair to the actors to condemn th...          0\n",
       "3  One of the most unheralded great works of anim...          1\n",
       "4  It was the Sixties, and anyone with long hair ...          0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample 수가 많으므로, 연산 분석용으로 대폭 줄여 새로운 파일을 만든 후 사용\n",
    "df = pd.read_csv('IMDb_Reviews_test.csv', encoding='latin1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 개수 : 20\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플의 개수 : {}'.format(len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련 데이터, 평가 데이터, 테스트 데이터로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[:15]\n",
    "test_df = df[15:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train_20_data.csv\", index=False)\n",
    "test_df.to_csv(\"test_20_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-2. Field 정의 및 Dataset 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(sequential=True,lower=True, batch_first=True)\n",
    "LABEL = data.Field(sequential=False, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = TabularDataset.splits(\n",
    "        path='.', train='train_20_data.csv', test='test_20_data.csv', format='csv',\n",
    "        fields=[('text', TEXT), ('label', LABEL)], skip_header=True)\n",
    "        # field: Data column format 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset sample 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플의 개수 : 15\n",
      "테스트 샘플의 개수 : 5\n"
     ]
    }
   ],
   "source": [
    "print('훈련 샘플의 개수 : {}'.format(len(trainset)))\n",
    "print('테스트 샘플의 개수 : {}'.format(len(testset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torchtext.data.example.Example object at 0x000001D063E22308>\n"
     ]
    }
   ],
   "source": [
    "print(trainset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['in', 'truth', 'though,', \"there's\", 'a', 'lack', 'of', 'dramatic', 'tension', 'throughout', 'for', 'which', 'the', 'action', 'sequences', \"don't\", 'fully', 'compensate', 'and', 'you', \"don't\", 'care', 'a', 'fig', 'for', 'any', 'of', 'the', 'leading', 'characters.', 'one', 'of', 'those', 'films', 'where', 'the', 'actors', 'probably', 'enjoyed', 'making', 'it', 'more', 'than', 'the', 'viewers', 'did', 'watching', 'it.'], 'label': '0'}\n"
     ]
    }
   ],
   "source": [
    "# trainset 내용물 확인\n",
    "print(vars(testset[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-3. Vocabulary set 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(trainset, min_freq=2)      # 단어 집합 생성, 단어 수가 적으므로 최소 횟수를 2로 설정\n",
    "LABEL.build_vocab(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 60\n"
     ]
    }
   ],
   "source": [
    "n_vocab = len(TEXT.vocab)\n",
    "print('단어 집합의 크기 : {}'.format(n_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x000001D063E213C8>>, {'<unk>': 0, '<pad>': 1, 'the': 2, 'of': 3, 'to': 4, 'and': 5, 'a': 6, 'it': 7, 'i': 8, 'one': 9, 'is': 10, 'this': 11, 'was': 12, 'in': 13, 'that': 14, 'but': 15, 'ever': 16, 'you': 17, 'are': 18, 'for': 19, 'movie': 20, 'be': 21, 'by': 22, 'first': 23, 'had': 24, \"it's\": 25, 'just': 26, 'make': 27, 'most': 28, 'movies': 29, 'not': 30, 'there': 31, 'they': 32, '/><br': 33, 'best': 34, 'could': 35, 'end': 36, 'far': 37, 'film': 38, 'films': 39, 'get': 40, 'happens': 41, 'have': 42, 'her': 43, 'if': 44, 'like': 45, 'makes': 46, 'many': 47, 'more': 48, 'movie.': 49, 'no,': 50, 'only': 51, 'really': 52, 'recommended.': 53, 'see': 54, 'seen.': 55, 'watch': 56, 'what': 57, 'with': 58, 'worse': 59})\n"
     ]
    }
   ],
   "source": [
    "# 수집된 전체 단어 확인\n",
    "print(TEXT.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_2, valset = trainset.split(split_ratio=0.75)       # 훈련 데이터와 평가 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플의 개수 : 11\n",
      "평가 샘플의 개수 : 4\n"
     ]
    }
   ],
   "source": [
    "print('훈련 샘플의 개수 : {}'.format(len(trainset_2)))\n",
    "print('평가 샘플의 개수 : {}'.format(len(valset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-4. Data loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "\n",
    "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
    "        (trainset_2, valset, testset), batch_size=BATCH_SIZE,\n",
    "        shuffle=True, repeat=False, sort=False)               \n",
    "        # shuffle 진행 안하면 Data 변환 추적 쉬움.\n",
    "        # data.BucketIterator.splits 조건에 sort=False를 하지 않으면\n",
    "        # \" '<' not supported ... \" Error 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 미니 배치의 개수 : 6\n",
      "검증 데이터의 미니 배치의 개수 : 2\n",
      "테스트 데이터의 미니 배치의 개수 : 3\n"
     ]
    }
   ],
   "source": [
    "print('훈련 데이터의 미니 배치의 개수 : {}'.format(len(train_iter)))\n",
    "print('검증 데이터의 미니 배치의 개수 : {}'.format(len(val_iter)))\n",
    "print('테스트 데이터의 미니 배치의 개수 : {}'.format(len(test_iter)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 2]\n",
      "\t[.text]:[torch.LongTensor of size 2x53]\n",
      "\t[.label]:[torch.LongTensor of size 2]\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_iter))       # Dataloader가 iterator 역할을 잘하는지 확인.\n",
    "print(batch)                         # 재실행 때마다 sample 크기 변해야 됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 2]\n",
      "\t[.text]:[torch.LongTensor of size 2x36]\n",
      "\t[.label]:[torch.LongTensor of size 2]\n"
     ]
    }
   ],
   "source": [
    "batch2 = next(iter(val_iter))\n",
    "print(batch2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 샘플의 개수 재확인 : 11\n",
      "검증 데이터의 샘플의 개수 재확인 : 4\n",
      "테스트 데이터의 샘플의 개수 재확인 : 5\n"
     ]
    }
   ],
   "source": [
    "print('훈련 데이터의 샘플의 개수 재확인 : {}'.format(len(train_iter.dataset)))\n",
    "print('검증 데이터의 샘플의 개수 재확인 : {}'.format(len(val_iter.dataset)))\n",
    "print('테스트 데이터의 샘플의 개수 재확인 : {}'.format(len(test_iter.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### batch Iterator test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b is 0. batch is \n",
      "[torchtext.data.batch.Batch of size 2]\n",
      "\t[.text]:[torch.LongTensor of size 2x31]\n",
      "\t[.label]:[torch.LongTensor of size 2]\n",
      "b is 1. batch is \n",
      "[torchtext.data.batch.Batch of size 2]\n",
      "\t[.text]:[torch.LongTensor of size 2x44]\n",
      "\t[.label]:[torch.LongTensor of size 2]\n",
      "b is 2. batch is \n",
      "[torchtext.data.batch.Batch of size 2]\n",
      "\t[.text]:[torch.LongTensor of size 2x25]\n",
      "\t[.label]:[torch.LongTensor of size 2]\n",
      "b is 3. batch is \n",
      "[torchtext.data.batch.Batch of size 2]\n",
      "\t[.text]:[torch.LongTensor of size 2x36]\n",
      "\t[.label]:[torch.LongTensor of size 2]\n",
      "b is 4. batch is \n",
      "[torchtext.data.batch.Batch of size 2]\n",
      "\t[.text]:[torch.LongTensor of size 2x53]\n",
      "\t[.label]:[torch.LongTensor of size 2]\n",
      "b is 5. batch is \n",
      "[torchtext.data.batch.Batch of size 1]\n",
      "\t[.text]:[torch.LongTensor of size 1x49]\n",
      "\t[.label]:[torch.LongTensor of size 1]\n"
     ]
    }
   ],
   "source": [
    "for b, batch in enumerate(train_iter):\n",
    "    x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n",
    "    print('b is {}. batch is {}'. format(b, batch))              # batch 개수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x is tensor([[ 0,  7,  0,  0, 11, 12,  0,  9,  0,  2,  0, 20,  8, 24, 16, 55,  0, 14,\n",
      "          0,  8, 42,  0, 47, 48, 29, 14, 18, 59,  0, 10,  7,  0,  0,  4, 21,  0,\n",
      "          8, 24,  4,  0, 11, 20,  6,  0,  0,  3,  0, 15,  7, 12,  6,  0,  0],\n",
      "        [11, 10,  0,  9,  3,  2, 28,  0,  0,  4,  6, 20,  8, 42, 16, 55, 19,  0,\n",
      "          3,  0,  0,  5,  0, 29, 25,  6,  0, 19,  2,  0,  3, 17, 25,  0, 53,  0,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1]]). y is tensor([2, 1])\n",
      "수정된 Y 값: tensor([1, 0])\n",
      "x is tensor([[ 2,  9,  0, 10,  2,  0,  4,  0, 13,  0,  0,  0,  0,  0,  0,  0,  4,  0,\n",
      "          0, 13,  2,  0,  0, 11, 26, 46,  2, 38,  6,  0,  0,  0, 15, 44, 17,  0,\n",
      "         54,  0,  0, 17,  0,  0,  6,  0,  0,  4,  0,  0, 53],\n",
      "        [ 2, 38,  0,  0, 13,  0,  0,  5,  0, 21, 51,  0, 13, 25,  0,  0,  0, 44,\n",
      "         17, 56, 14,  0,  0,  0,  0,  0, 33,  0,  0, 33,  0,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1]]). y is tensor([1, 2])\n",
      "수정된 Y 값: tensor([0, 1])\n",
      "x is tensor([[ 0,  6,  0,  0,  3,  0,  0,  0,  0, 31, 12,  3,  0,  0,  0,  0,  0, 14,\n",
      "          8, 24,  4, 54, 11,  0]]). y is tensor([1])\n",
      "수정된 Y 값: tensor([0])\n",
      "x is tensor([[ 8,  0,  2, 36,  3, 11,  5,  8, 12,  0,  0,  0, 50, 50,  0,  7,  0, 36,\n",
      "          0, 31, 18,  0, 47,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1],\n",
      "        [ 7, 10,  0,  5,  8,  0,  7,  4,  0, 17, 52,  0, 58,  0,  5,  0,  5,  0,\n",
      "          0,  0, 19, 43,  5,  0,  3, 57, 41,  4,  0,  8,  0,  7,  0,  0,  5,  0,\n",
      "          8,  0,  4,  0, 57, 41,  0]]). y is tensor([1, 1])\n",
      "수정된 Y 값: tensor([0, 0])\n",
      "x is tensor([[ 0,  0,  3,  0,  0,  6,  0,  0,  0,  0, 13,  6,  0,  3,  0,  0, 22, 43,\n",
      "          0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1],\n",
      "        [31, 10,  0,  0, 14,  0, 10, 22, 37,  9,  3,  2, 34, 39, 16, 30, 51, 13,\n",
      "          0,  0, 15,  0,  0,  0,  2, 39,  0,  0, 45,  2,  0,  7, 35,  0,  0,  0,\n",
      "          3,  0, 46,  7,  0,  4,  0,  0]]). y is tensor([1, 1])\n",
      "수정된 Y 값: tensor([0, 0])\n",
      "x is tensor([[ 7, 12,  2,  0,  5,  0, 58,  0,  0,  5,  6,  0,  0,  0, 35, 40,  0,  4,\n",
      "         27,  6, 49,  0,  0,  0,  0,  0,  3, 11,  0,  0, 12,  0,  4, 40,  2,  0,\n",
      "          0, 10,  9,  3,  2, 28,  0,  0,  0, 16,  0,  6,  0,  4, 27,  6, 49],\n",
      "        [ 0,  0,  5,  8,  0,  0, 30, 56,  0, 29, 19,  2,  0,  0, 14, 32, 18,  0,\n",
      "          0, 32,  0,  2,  0,  5, 26, 30,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1]]). y is tensor([2, 1])\n",
      "수정된 Y 값: tensor([1, 0])\n"
     ]
    }
   ],
   "source": [
    "for b, batch in enumerate(train_iter):\n",
    "    x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n",
    "    print('x is {}. y is {}'. format(x, y)) \n",
    "    print('수정된 Y 값:' , y.data.sub_(1))    # lable 값 조정: y값에서 () 값을 뺌, sub 대신 add를 하면 더함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7, 12,  2,  0,  5,  0, 58,  0,  0,  5,  6,  0,  0,  0, 35, 40,  0,  4,\n",
       "         27,  6, 49,  0,  0,  0,  0,  0,  3, 11,  0,  0, 12,  0,  4, 40,  2,  0,\n",
       "          0, 10,  9,  3,  2, 28,  0,  0,  0, 16,  0,  6,  0,  4, 27,  6, 49],\n",
       "        [ 0,  0,  5,  8,  0,  0, 30, 56,  0, 29, 19,  2,  0,  0, 14, 32, 18,  0,\n",
       "          0, 32,  0,  2,  0,  5, 26, 30,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,\n",
       "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " x            # 현재 x 입력값 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 53])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " x.shape  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-5. Reviewing RNN, GRU Model\n",
    "\n",
    "* Embedding, RNN/GRU, Cost Function 동작 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 2     # 분류되어야 할 결과 수 (긍정 or 부정)\n",
    "embed_dim= 8      # 임베딩 된 차원의 크기 : RNN 층 입력 차원의 크기가 됨\n",
    "hidden_size = 6  # RNN의 은닉층 크기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60, 8])\n",
      "Parameter containing:\n",
      "tensor([[ 1.8423e+00,  5.1889e-01, -1.7119e+00, -1.7014e+00,  2.0194e+00,\n",
      "         -2.6861e-01, -1.3072e-01, -1.4374e+00],\n",
      "        [ 3.9077e-01, -1.8968e-02, -1.3527e+00, -7.3082e-01,  9.8792e-01,\n",
      "         -4.1941e-01, -5.8490e-01, -7.8233e-01],\n",
      "        [ 2.7799e+00,  1.2220e+00, -3.3645e-01, -9.6506e-01, -1.2966e-01,\n",
      "         -6.0177e-01,  1.4500e-01, -1.4983e-01],\n",
      "        [-4.3740e-01,  7.7923e-01, -5.8339e-02, -2.0305e+00,  1.4829e+00,\n",
      "          4.9404e-01,  2.4922e-01,  1.7470e+00],\n",
      "        [-2.6167e-01, -7.3239e-01,  1.6980e+00, -1.7917e-01,  1.9231e+00,\n",
      "          2.8795e-01,  9.3680e-01, -2.4031e+00],\n",
      "        [-1.4789e-01,  8.9670e-01,  5.4813e-01, -1.6391e+00, -1.8153e+00,\n",
      "         -2.0663e-01, -5.2595e-01, -1.6977e+00],\n",
      "        [ 8.1679e-01,  4.0964e-01,  2.1623e-01,  1.0898e+00,  1.7303e-01,\n",
      "          1.6677e-01, -1.1372e+00, -8.2083e-01],\n",
      "        [-1.7927e+00,  8.7719e-01,  2.1641e+00, -1.8553e-01,  9.9064e-01,\n",
      "          7.4259e-01,  1.2702e+00,  1.3227e+00],\n",
      "        [-5.1811e-01,  1.5633e+00,  1.2358e+00,  1.4962e+00,  4.7312e-01,\n",
      "          6.0702e-01, -8.7793e-01, -7.4259e-01],\n",
      "        [ 2.8316e-01, -1.4981e+00, -3.0913e-01, -6.0410e-01, -1.9672e+00,\n",
      "         -1.3676e-01,  1.8703e+00,  1.5050e-01],\n",
      "        [-8.1565e-01, -3.8387e-01,  4.0206e-01, -1.4338e+00, -7.2579e-02,\n",
      "         -5.4705e-01,  4.8782e-01, -6.5195e-01],\n",
      "        [-3.6421e-01,  1.0474e+00,  9.9757e-01,  9.2672e-01,  1.9252e+00,\n",
      "         -4.7434e-02,  5.1863e-01,  6.5188e-01],\n",
      "        [-8.3233e-01, -1.8556e-01,  1.2361e+00, -1.4389e+00, -8.9084e-01,\n",
      "         -2.5974e-01, -2.3202e-01,  4.4492e-01],\n",
      "        [ 2.5572e-01,  1.0455e+00,  1.7144e+00, -1.2035e+00, -1.8259e-01,\n",
      "          1.3226e-01,  5.0329e-01, -2.2264e-01],\n",
      "        [-1.1186e-01, -2.1019e-01,  9.2921e-01, -7.4944e-01,  4.4238e-02,\n",
      "          1.0023e+00, -1.5020e+00, -1.3211e+00],\n",
      "        [-1.5640e-01,  1.1380e+00, -1.3308e+00,  1.8092e+00,  3.6398e-01,\n",
      "         -3.0125e-01, -1.6497e+00,  2.8655e-02],\n",
      "        [ 3.8647e-01,  9.6968e-01,  1.9006e-01,  1.8483e-01,  8.8378e-01,\n",
      "          1.3211e+00, -1.3169e-01, -1.4731e+00],\n",
      "        [-4.2345e-01,  2.1471e-01, -4.5853e-01,  5.6842e-01,  5.8099e-01,\n",
      "         -2.6558e-01,  4.1469e-01,  2.5220e+00],\n",
      "        [-1.2157e+00, -1.7087e-02, -4.8851e-01,  9.5343e-01, -8.8934e-01,\n",
      "          7.3870e-01, -5.2488e-01, -5.0940e-02],\n",
      "        [-4.1782e-01, -1.7469e+00,  1.1436e+00,  3.4803e-02,  8.7896e-01,\n",
      "          7.5425e-02,  1.3254e-01, -1.4096e+00],\n",
      "        [ 4.7585e-01,  1.5379e+00,  7.6975e-01,  1.5764e+00, -1.4288e+00,\n",
      "         -1.1835e+00,  1.2763e+00,  8.3973e-01],\n",
      "        [-1.1636e+00, -8.5256e-01,  1.0985e+00, -1.4595e-01, -1.9882e+00,\n",
      "          5.5488e-01,  3.4823e-01,  1.6954e-03],\n",
      "        [-4.5721e-01, -3.5527e-01, -4.9952e-01,  3.6492e-01,  6.0476e-02,\n",
      "          7.8660e-02, -5.3181e-01, -4.0552e-01],\n",
      "        [ 1.3347e-01, -2.1064e-01, -3.3896e-01, -8.6137e-01, -4.1705e-01,\n",
      "          4.0613e-01,  9.4468e-01, -2.9228e-02],\n",
      "        [ 7.6481e-01, -1.6380e+00,  3.8242e-01, -6.9217e-01,  5.2519e-01,\n",
      "         -1.4957e+00,  6.7110e-02,  2.0938e-01],\n",
      "        [ 2.1251e+00, -1.7762e-01,  5.9260e-01, -8.2783e-01, -1.2285e+00,\n",
      "          5.1336e-02, -8.6594e-01, -2.8724e-01],\n",
      "        [ 1.4718e+00,  1.0551e-01,  1.7005e+00, -1.3800e+00, -6.2689e-02,\n",
      "         -3.1308e-01,  5.6841e-01,  1.7646e+00],\n",
      "        [-1.1201e+00,  1.9252e-01,  1.7974e+00, -3.1003e-01,  6.8853e-02,\n",
      "         -1.3640e+00,  1.2411e-01, -1.8627e+00],\n",
      "        [-9.9629e-01,  2.3225e-01,  5.5325e-01, -4.7744e-01,  1.5283e+00,\n",
      "          2.8549e+00, -2.9776e-01,  2.5957e-01],\n",
      "        [-7.6262e-01, -1.1713e+00,  3.0566e-01,  1.1343e+00,  1.1514e+00,\n",
      "         -7.4342e-01,  5.4672e-01, -7.8664e-01],\n",
      "        [-8.2039e-01,  1.1981e+00, -1.0110e-01,  1.5047e+00, -6.1868e-01,\n",
      "         -1.6642e+00, -3.3206e-01,  9.6409e-01],\n",
      "        [-1.5128e+00,  3.8009e-01,  1.3454e+00,  1.1067e+00,  8.7498e-01,\n",
      "          3.3316e-01, -1.0130e+00,  6.9896e-01],\n",
      "        [ 1.9494e-01,  1.5408e+00, -6.6034e-01,  7.5358e-01,  1.1950e-01,\n",
      "          8.8753e-01,  5.3275e-01, -1.5943e-01],\n",
      "        [ 3.6350e-01, -1.1753e+00, -8.5157e-01,  1.0821e-02,  9.7814e-01,\n",
      "         -8.4155e-01, -6.8785e-02, -1.1494e-01],\n",
      "        [-1.6556e+00, -3.3415e-01, -1.6154e+00,  4.1056e-01,  9.6385e-01,\n",
      "          3.2822e-01,  6.0499e-02, -1.1918e+00],\n",
      "        [-5.1907e-01, -1.2785e+00,  7.2213e-01,  2.4976e-01, -9.0842e-01,\n",
      "          9.5101e-02,  1.1338e-01, -1.9077e+00],\n",
      "        [-6.3588e-01, -1.2286e+00,  1.0538e-01, -2.6915e-01, -5.8623e-01,\n",
      "         -2.7735e-01, -1.0781e+00,  4.1353e-01],\n",
      "        [ 5.9194e-01,  7.1071e-01, -2.6220e-01,  1.5016e+00, -1.6780e-01,\n",
      "          1.7115e+00, -1.1779e-01, -1.6749e-01],\n",
      "        [ 1.5554e+00, -1.2570e+00, -1.3365e-01,  1.1172e-01, -1.8766e+00,\n",
      "         -1.3434e+00, -2.0549e+00, -6.5486e-01],\n",
      "        [-3.0384e-01,  5.3760e-01,  2.6860e-01, -1.7700e+00,  2.1069e+00,\n",
      "          4.1004e-01,  8.5395e-01,  1.4541e+00],\n",
      "        [ 1.2122e+00,  2.4890e-01,  6.1895e-01,  1.5857e+00,  1.2450e-01,\n",
      "          7.2988e-01,  2.3823e+00, -6.4852e-01],\n",
      "        [ 5.7090e-01, -9.8027e-01, -5.2283e-02, -1.9604e+00,  1.8087e-01,\n",
      "          5.9323e-02,  8.0891e-01,  6.6787e-02],\n",
      "        [ 1.2781e+00,  5.8572e-01,  1.3827e+00,  6.9413e-01, -1.1786e+00,\n",
      "          2.7774e-01, -8.1172e-01, -2.7757e-01],\n",
      "        [-5.4897e-01, -1.0008e+00, -3.2591e-01, -4.0876e-01, -4.0726e-02,\n",
      "         -2.4222e+00, -4.0392e-01, -4.3812e-01],\n",
      "        [-9.7435e-01,  9.6390e-01, -1.9119e-01,  1.0727e+00,  1.6019e+00,\n",
      "          9.7960e-01, -1.0462e+00, -5.4480e-01],\n",
      "        [ 7.3525e-01,  1.4416e+00,  9.1334e-01,  2.2624e-01, -6.4701e-01,\n",
      "          1.1707e+00,  1.8681e+00, -8.0578e-01],\n",
      "        [-1.9958e+00,  4.4373e-01, -2.2359e+00, -1.1041e+00,  7.7269e-01,\n",
      "         -1.0041e-01, -8.0114e-01, -6.9784e-01],\n",
      "        [ 3.3017e-01, -1.7603e+00,  8.6129e-01, -2.7275e-01,  2.9520e-01,\n",
      "         -8.6370e-02, -1.0778e+00,  1.3174e+00],\n",
      "        [ 2.5975e-01, -2.2675e-01,  1.0719e+00,  1.3769e-01,  1.3735e+00,\n",
      "          8.9003e-01,  5.2056e-03,  1.0246e+00],\n",
      "        [-1.4377e+00,  2.6753e-02,  1.7635e+00,  2.2781e-01, -1.2651e+00,\n",
      "          2.7658e-01,  1.4019e-01,  2.7095e-01],\n",
      "        [ 5.0731e-02,  1.7496e+00,  3.8432e-01, -4.1870e-01, -6.1326e-01,\n",
      "         -2.0183e-01, -9.0321e-01,  1.4338e-01],\n",
      "        [ 1.8738e-01, -1.9101e+00,  7.3128e-01, -1.0993e+00,  8.1239e-01,\n",
      "         -3.8308e-01,  6.2751e-01, -3.9471e-01],\n",
      "        [-2.1197e+00,  1.6773e+00,  2.8148e-01, -6.9085e-01, -1.6099e+00,\n",
      "         -4.9261e-01,  2.3397e-01,  1.7376e+00],\n",
      "        [ 1.0201e+00, -1.6660e+00, -2.0331e+00,  5.2428e-01,  8.1233e-01,\n",
      "          2.9064e-01,  9.4832e-02, -1.5761e+00],\n",
      "        [-3.6960e-01,  9.2121e-01,  1.3179e+00,  2.8796e-01,  6.7307e-01,\n",
      "          2.1551e+00,  2.8432e-01, -3.2210e-01],\n",
      "        [-5.8949e-01, -1.2183e+00,  2.3109e+00, -3.4027e-01, -6.3871e-02,\n",
      "         -3.7241e-01, -1.0717e+00, -6.9002e-02],\n",
      "        [-1.1593e+00, -8.1672e-01,  3.0819e-01,  2.5358e-01,  1.6119e+00,\n",
      "         -2.1664e-01, -6.7991e-01,  7.3018e-01],\n",
      "        [-1.0188e+00, -3.7104e-01,  1.2736e+00,  7.2057e-01,  1.1408e+00,\n",
      "          8.6899e-01,  2.0888e-01, -7.6564e-01],\n",
      "        [-6.1839e-01, -3.9622e-01,  4.9711e-01,  7.7949e-01,  1.1942e-01,\n",
      "          1.3390e-02,  6.1887e-02,  1.1370e-01],\n",
      "        [-4.3898e-01, -1.0939e+00,  5.6871e-01,  6.4885e-02,  7.0424e-01,\n",
      "          1.0799e-01,  6.3964e-01, -1.0614e+00]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# num_embedding는 trainset 단어 전체 갯수인 n_vocab로 지정\n",
    "Emb_Test=nn.Embedding(num_embeddings=n_vocab,   embedding_dim=embed_dim)\n",
    "\n",
    "# 가중치 확인\n",
    "print(Emb_Test.weight.shape)   # (단어갯수, embedding dim)\n",
    "print(Emb_Test.weight)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 53, 8])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Emb_Test(x).shape           # 임베딩 결과 차원 확인 : (batch 크기 x 문장 단어 크기 x embedding 크기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Emb_Test(x).size(0)        # batch size 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN input Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x000001D063E25548>\n",
      "torch.Size([6, 8])\n"
     ]
    }
   ],
   "source": [
    "rnn_test = nn.RNN(embed_dim, hidden_size, batch_first=True) \n",
    "\n",
    "# model에 구성된 파라미터 가중치 확인 : 추가 분석은 아래 참고\n",
    "print(rnn_test.parameters())\n",
    "print(next(rnn_test.parameters()).shape)     # 벡터 크기 : (hidden_size, embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 53, 6])\n",
      "torch.Size([1, 2, 6])\n"
     ]
    }
   ],
   "source": [
    "output_rnn, hidden_rnn = rnn_test (Emb_Test(x))      # Tuple 형태의 결과를 분리\n",
    "print(output_rnn.shape)                # (batch 크기 x 문장 길이 x 은닉층 크기)\n",
    "print(hidden_rnn.shape)                # (층 크기 x batch 크기 x 은닉층 크기)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU input Test\n",
    "* 긴 문장에서는 RNN보다 GRU가 더 나은 결과를 보임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x000001D063E25D48>\n",
      "torch.Size([18, 8])\n"
     ]
    }
   ],
   "source": [
    "gru_test = nn.GRU(embed_dim, hidden_size, batch_first=True)\n",
    "\n",
    "# model에 구성된 파라미터 가중치 확인 : 추가 분석은 아래 참고\n",
    "print(gru_test.parameters())                # RNN과 parameter 벡터가 다름\n",
    "print(next(gru_test.parameters()).shape)    # (hidden_size x3 , embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 53, 6])\n",
      "torch.Size([1, 2, 6])\n"
     ]
    }
   ],
   "source": [
    "output_gru, hidden_gru = gru_test (Emb_Test(x))      # Tuple 형태의 결과를 분리\n",
    "print(output_gru.shape)             # 결과와 은닉 가중치 벡터 크기는 RNN과 동일\n",
    "print(hidden_gru.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5692,  0.5825, -0.6861, -0.2384,  0.1169,  0.4754],\n",
       "         [ 0.4129,  0.8338, -0.6284,  0.7119,  0.0733,  0.1744],\n",
       "         [ 0.9365, -0.5986,  0.8250,  0.8036,  0.8741, -0.3218],\n",
       "         [ 0.9942, -0.8088,  0.7827,  0.4465,  0.8710, -0.1135],\n",
       "         [ 0.6206,  0.5289,  0.3518,  0.7245,  0.9080, -0.6963],\n",
       "         [ 0.9959, -0.8320,  0.8869,  0.5873,  0.8435,  0.3685],\n",
       "         [ 0.0807, -0.0792,  0.4226, -0.8140,  0.0791, -0.1991],\n",
       "         [ 0.9876, -0.7124,  0.4210,  0.8327,  0.5429,  0.6553],\n",
       "         [ 0.9958, -0.5658,  0.5685,  0.2875,  0.8314, -0.3111],\n",
       "         [ 0.6142,  0.5468,  0.4286,  0.7706,  0.9084, -0.5523],\n",
       "         [ 0.6119, -0.7902,  0.9009, -0.6016,  0.3985,  0.3108],\n",
       "         [ 0.9865, -0.6085,  0.2863,  0.6835,  0.6127,  0.1683],\n",
       "         [ 0.9955, -0.6410,  0.6886,  0.4448,  0.8511, -0.0617],\n",
       "         [ 0.9938, -0.7132,  0.7163,  0.4934,  0.8325, -0.0740],\n",
       "         [ 0.4445, -0.3917,  0.9262, -0.7782,  0.6859, -0.3345],\n",
       "         [-0.4005, -0.9336,  0.9867, -0.4249,  0.2972, -0.1739],\n",
       "         [ 0.9893, -0.8713,  0.3394,  0.8533,  0.4954,  0.2472],\n",
       "         [ 0.9191, -0.8691,  0.8963, -0.9143,  0.9277, -0.1657],\n",
       "         [ 0.5625, -0.5490,  0.1644,  0.1475,  0.7889,  0.4184],\n",
       "         [ 0.6110, -0.5269,  0.6864, -0.4766,  0.0716, -0.0111],\n",
       "         [-0.8620,  0.6903, -0.3605, -0.3045,  0.1620,  0.1212],\n",
       "         [ 0.9967, -0.7696,  0.5806,  0.8889,  0.2992,  0.6559],\n",
       "         [ 0.9948, -0.5920,  0.4817,  0.2139,  0.8474, -0.2932],\n",
       "         [ 0.9934, -0.7068,  0.7489,  0.6069,  0.8312,  0.1405],\n",
       "         [ 0.9943, -0.7014,  0.6842,  0.4125,  0.8329, -0.2185],\n",
       "         [ 0.9933, -0.7391,  0.7309,  0.5325,  0.8435, -0.0107],\n",
       "         [ 0.5991,  0.8477, -0.8237,  0.3481,  0.4362, -0.2744],\n",
       "         [ 0.6326, -0.4661,  0.4409, -0.4824,  0.2578,  0.8538],\n",
       "         [ 0.9912, -0.3705,  0.2018,  0.6122,  0.5642,  0.1439],\n",
       "         [ 0.9954, -0.6146,  0.7016,  0.4507,  0.8458,  0.0579],\n",
       "         [ 0.0327,  0.7890, -0.4396,  0.1083,  0.6986, -0.5645],\n",
       "         [ 0.9970, -0.7731,  0.8569,  0.8261,  0.6909,  0.6666],\n",
       "         [ 0.9089, -0.8565,  0.8657, -0.9416,  0.8991, -0.4406],\n",
       "         [-0.4573, -0.9115,  0.9881, -0.4274,  0.4262, -0.2312],\n",
       "         [ 0.7790, -0.8874,  0.5569,  0.9451,  0.6528, -0.6126],\n",
       "         [ 0.9948, -0.8547,  0.7932,  0.5633,  0.8984,  0.0157],\n",
       "         [ 0.9940, -0.7301,  0.6999,  0.4601,  0.8381, -0.2230],\n",
       "         [ 0.7657,  0.2492,  0.2582,  0.1223,  0.7947, -0.1815],\n",
       "         [ 0.1086,  0.3256,  0.9578,  0.1368,  0.4517, -0.5228],\n",
       "         [ 0.4594,  0.6815, -0.8217,  0.6038,  0.1314,  0.3231],\n",
       "         [ 0.9435, -0.5082,  0.8122,  0.8213,  0.8635, -0.3535],\n",
       "         [-0.1646,  0.7765,  0.1361, -0.8760,  0.1282, -0.2159],\n",
       "         [ 0.9907, -0.6978,  0.5543,  0.8541,  0.4229,  0.7776],\n",
       "         [ 0.9953, -0.5534,  0.4939,  0.2102,  0.8275, -0.3441],\n",
       "         [ 0.9931, -0.7158,  0.7544,  0.6084,  0.8348,  0.1733],\n",
       "         [ 0.6755, -0.3544,  0.7904, -0.6292,  0.6257, -0.3748],\n",
       "         [ 0.9865, -0.7136,  0.6055,  0.7493,  0.6877,  0.4515],\n",
       "         [ 0.5564, -0.5727,  0.6880, -0.7448,  0.3857, -0.2828],\n",
       "         [ 0.9854, -0.6962,  0.4821,  0.7836,  0.6631,  0.4912],\n",
       "         [ 0.9223, -0.8485,  0.8910, -0.9250,  0.9073, -0.2796],\n",
       "         [ 0.5464, -0.5741,  0.1958,  0.1710,  0.7996,  0.4664],\n",
       "         [ 0.6165, -0.5284,  0.6772, -0.4878,  0.0592, -0.0532],\n",
       "         [-0.8647,  0.6855, -0.3529, -0.2938,  0.1734,  0.1462]],\n",
       "\n",
       "        [[ 0.9943, -0.7273,  0.5321,  0.7668,  0.6650,  0.5295],\n",
       "         [ 0.9955, -0.6062,  0.6066,  0.3214,  0.8288, -0.3112],\n",
       "         [ 0.6115,  0.5336,  0.4233,  0.7650,  0.9104, -0.5706],\n",
       "         [ 0.0970, -0.6204,  0.6991, -0.6846,  0.3544,  0.5347],\n",
       "         [ 0.9902, -0.6296,  0.2065,  0.7718,  0.4199,  0.1871],\n",
       "         [ 0.9954, -0.6332,  0.6584,  0.4169,  0.8663, -0.0178],\n",
       "         [ 0.0343, -0.2345, -0.2009,  0.0475, -0.1792,  0.5451],\n",
       "         [ 0.6141,  0.3250, -0.7415, -0.6935, -0.5492,  0.8195],\n",
       "         [ 0.9927, -0.0161,  0.1607,  0.6962,  0.6059,  0.7295],\n",
       "         [ 0.8437, -0.6368,  0.7821, -0.9369,  0.1586,  0.5105],\n",
       "         [ 0.3349, -0.2867,  0.4620, -0.8651,  0.3130,  0.3488],\n",
       "         [ 0.7596, -0.5580,  0.4846,  0.9058,  0.6566, -0.4489],\n",
       "         [ 0.9952, -0.8255,  0.7929,  0.5318,  0.8816,  0.0530],\n",
       "         [ 0.9939, -0.7188,  0.6889,  0.4561,  0.8325, -0.2155],\n",
       "         [ 0.4712,  0.3361,  0.3658, -0.5745,  0.7148, -0.3683],\n",
       "         [ 0.0959, -0.0299,  0.7471,  0.3556, -0.2831,  0.5687],\n",
       "         [-0.4056,  0.6372, -0.1683, -0.6556, -0.6751,  0.4277],\n",
       "         [ 0.9916, -0.5833,  0.1414,  0.8148,  0.3913,  0.7723],\n",
       "         [ 0.9963, -0.4734,  0.5418,  0.2927,  0.8294, -0.2172],\n",
       "         [ 0.2263, -0.0575,  0.7699, -0.0449,  0.1537,  0.0781],\n",
       "         [ 0.9905, -0.7537,  0.4623,  0.6480,  0.6610,  0.3387],\n",
       "         [ 0.8856, -0.6413,  0.7415,  0.7169,  0.8989, -0.8175],\n",
       "         [ 0.9937, -0.8609,  0.8385,  0.5833,  0.8901,  0.0997],\n",
       "         [ 0.6530,  0.5531,  0.3040,  0.6770,  0.9053, -0.7673],\n",
       "         [ 0.1049, -0.2586,  0.5468,  0.4321,  0.8822, -0.6478],\n",
       "         [ 0.1665, -0.6485,  0.0380,  0.4667, -0.3478,  0.7267],\n",
       "         [ 0.9950, -0.6174,  0.2049,  0.5896,  0.7234,  0.1370],\n",
       "         [ 0.9957, -0.6255,  0.7130,  0.4956,  0.8426, -0.0435],\n",
       "         [ 0.9938, -0.7173,  0.7160,  0.4718,  0.8355, -0.0951],\n",
       "         [ 0.9511, -0.2699,  0.4138,  0.0198,  0.4518,  0.2540],\n",
       "         [ 0.9423,  0.0496,  0.1882,  0.0565,  0.2796,  0.5084],\n",
       "         [ 0.9499,  0.2088,  0.1275, -0.0209,  0.2405,  0.5585],\n",
       "         [ 0.9493,  0.2690,  0.1141, -0.0239,  0.2066,  0.6030],\n",
       "         [ 0.9493,  0.2923,  0.0965, -0.0419,  0.1963,  0.6105],\n",
       "         [ 0.9492,  0.3038,  0.0925, -0.0385,  0.1900,  0.6200],\n",
       "         [ 0.9494,  0.3080,  0.0899, -0.0430,  0.1889,  0.6206],\n",
       "         [ 0.9493,  0.3100,  0.0895, -0.0419,  0.1875,  0.6224],\n",
       "         [ 0.9493,  0.3106,  0.0889, -0.0430,  0.1874,  0.6224],\n",
       "         [ 0.9493,  0.3110,  0.0889, -0.0426,  0.1871,  0.6228],\n",
       "         [ 0.9493,  0.3111,  0.0887, -0.0429,  0.1872,  0.6228],\n",
       "         [ 0.9493,  0.3112,  0.0887, -0.0428,  0.1871,  0.6228],\n",
       "         [ 0.9493,  0.3112,  0.0887, -0.0429,  0.1871,  0.6228],\n",
       "         [ 0.9493,  0.3112,  0.0887, -0.0428,  0.1871,  0.6228],\n",
       "         [ 0.9493,  0.3112,  0.0887, -0.0429,  0.1871,  0.6228],\n",
       "         [ 0.9493,  0.3112,  0.0887, -0.0428,  0.1871,  0.6228],\n",
       "         [ 0.9493,  0.3112,  0.0887, -0.0429,  0.1871,  0.6228],\n",
       "         [ 0.9493,  0.3112,  0.0887, -0.0429,  0.1871,  0.6228],\n",
       "         [ 0.9493,  0.3112,  0.0887, -0.0429,  0.1871,  0.6228],\n",
       "         [ 0.9493,  0.3112,  0.0887, -0.0429,  0.1871,  0.6228],\n",
       "         [ 0.9493,  0.3112,  0.0887, -0.0429,  0.1871,  0.6228],\n",
       "         [ 0.9493,  0.3112,  0.0887, -0.0429,  0.1871,  0.6228],\n",
       "         [ 0.9493,  0.3112,  0.0887, -0.0429,  0.1871,  0.6228],\n",
       "         [ 0.9493,  0.3112,  0.0887, -0.0429,  0.1871,  0.6228]]],\n",
       "       grad_fn=<TransposeBackward1>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_rnn"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return Analysis\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "* 리뷰 감성 분류는 긍정/부정 하나의 분류이므로, RNN 다대일 구조이며, 이 경우 RNN 연산 결과는 n개 은닉 상태 중에서 마지막 번째만 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8647,  0.6855, -0.3529, -0.2938,  0.1734,  0.1462],\n",
      "        [ 0.9493,  0.3112,  0.0887, -0.0429,  0.1871,  0.6228]],\n",
      "       grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "x_out = output_rnn[:, -1, :]\n",
    "print(x_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.2353,  0.0000, -0.5042, -0.0000,  0.2478,  0.2089],\n",
      "        [ 1.3562,  0.4446,  0.0000, -0.0612,  0.2673,  0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "dropout_p=0.3         # '0'은 dropout이 없고, '1'이면 모두 zero로 만듬\n",
    "dropout = nn.Dropout(dropout_p)\n",
    "x_out = dropout(x_out)\n",
    "print(x_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression test for Binary Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4373, -0.2018],\n",
       "        [-0.1927,  0.7488]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_test = nn.Linear(hidden_size, n_classes)\n",
    "out=linear_test(x_out)\n",
    "out                          # (batch 크기 x 분류 갯수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.2510, -0.3586, -0.3861, -0.3712, -0.3518,  0.3240],\n",
       "        [ 0.3765, -0.2576,  0.1041, -0.2520,  0.0994, -0.0942]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가중치 확인\n",
    "print(linear_test.weight.shape)\n",
    "linear_test.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing selection results with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([-0.2018,  0.7488], grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1]))\n",
      "결과값 :  tensor([1, 1])\n"
     ]
    }
   ],
   "source": [
    "# 0과 1에서 높은 확률값 선택\n",
    "print(out.max(1))\n",
    "print(\"결과값 : \", out.max(1)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y     # 현재 Label값들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# out값을 y차원에 맞춰 다시 정렬\n",
    "out.max(1)[1].view(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# out값과 Label이 맞는 갯수\n",
    "(out.max(1)[1].view(y.size()).data == y.data).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9266, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss = F.cross_entropy(out, y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9265848398208618"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss 값만 출력하는 방법\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-6. Designing Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Modeling\n",
    "\n",
    "* 연산 순서: Embedding -> GRU (or RNN) -> binary Classification\n",
    "* 긴 문장이되면 동일 하이파라미터 조건에서도 RNN보다 GRU가 우수하므로 아래는 GRU로 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myModel(nn.Module):\n",
    "    def __init__(self, hidden_size, n_vocab, embed_dim, n_classes, dropout_p, batch_first=True):    \n",
    "        super(myModel, self).__init__()\n",
    "        self.embedding_layer = nn.Embedding(num_embeddings=n_vocab, embedding_dim=embed_dim)\n",
    "        self.gru_layer = nn.GRU(embed_dim, hidden_size, batch_first=batch_first)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.linear = nn.Linear(hidden_size, n_classes) \n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.embedding_layer(x)\n",
    "        output, hidden = self.gru_layer(output)\n",
    "        x_out = self.dropout(output[:, -1, :])\n",
    "        output = self.linear(x_out)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "simple_model = myModel(hidden_size, n_vocab, embed_dim, n_classes, dropout_p, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1316,  0.4168],\n",
       "        [-0.3249,  0.5030]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model(x)           # x 입력하여 Model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=simple_model.parameters(), lr = 0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04/20] output is tensor([[0.3908, 0.3216],\n",
      "        [0.1951, 0.1914]]), y is tensor([0, 1]), and loss is 1.3542 \n",
      "[08/20] output is tensor([[0.6100, 0.1296]]), y is tensor([0]), and loss is 0.4815 \n",
      "[12/20] output is tensor([[ 0.0225,  0.3530],\n",
      "        [ 1.4272, -0.0599]]), y is tensor([1, 0]), and loss is 0.7453 \n",
      "[16/20] output is tensor([[-0.9457,  0.2627],\n",
      "        [ 1.7903, -0.4940]]), y is tensor([1, 0]), and loss is 0.3583 \n",
      "[20/20] output is tensor([[ 2.2426, -0.0988],\n",
      "        [ 2.5719, -0.3834]]), y is tensor([0, 1]), and loss is 3.0979 \n"
     ]
    }
   ],
   "source": [
    "for step in range(1, 21):\n",
    "        for b, batch in enumerate(train_iter):\n",
    "            x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n",
    "            y.data.sub_(1)                  # lable 값 0 또는 1로 조정\n",
    "            optimizer.zero_grad()\n",
    "            output = simple_model(x)\n",
    "            loss = F.cross_entropy(output, y, reduction='sum')\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if step % 4 == 0:\n",
    "            print(\"[{:02d}/20] output is {}, y is {}, and loss is {:.4f} \".format(step, output.data, y, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-7. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss is 1.5193177461624146, val accuracy is 25.0\n"
     ]
    }
   ],
   "source": [
    "corrects, total_loss = 0, 0\n",
    "for b, batch in enumerate(val_iter):\n",
    "    x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n",
    "    y.data.sub_(1)\n",
    "    output = simple_model(x)\n",
    "    loss = F.cross_entropy(output, y, reduction='sum')\n",
    "    total_loss += loss.item()              # loss 누적 값\n",
    "    corrects += (output.max(1)[1].view(y.size()).data == y.data).sum()     # 정답 맞춘 총횟수\n",
    "size = len(val_iter.dataset)\n",
    "avg_loss = total_loss / size\n",
    "avg_accuracy = 100.0 * corrects / size\n",
    "print(\"val loss is {}, val accuracy is {}\".format (avg_loss, avg_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 참고: Model의 가중치(Parameters) 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x000001D063E255C8>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 가중치\n",
    "simple_model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 3.0864e-01,  9.8647e-01,  1.3314e+00, -5.8387e-01, -5.3893e-01,\n",
       "           8.6339e-02, -7.3325e-01,  1.2195e+00],\n",
       "         [ 7.5774e-01,  1.4066e+00,  4.3821e-01, -6.8423e-01, -4.2995e-01,\n",
       "          -9.5826e-01, -4.1490e-02, -1.4533e+00],\n",
       "         [-1.0715e-01,  9.2046e-01,  1.2394e+00, -8.8895e-04, -1.5224e+00,\n",
       "          -1.9200e-01,  3.9307e-01, -7.6895e-01],\n",
       "         [ 8.7640e-01,  6.1190e-02, -1.7413e-01,  1.4305e+00, -3.4882e-01,\n",
       "          -1.0501e+00, -1.4155e-01, -1.0586e-02],\n",
       "         [ 5.7630e-01,  3.7684e-01, -1.0586e+00,  3.8520e-01,  7.5463e-02,\n",
       "          -7.8259e-01, -8.2497e-01,  2.1316e-01],\n",
       "         [ 7.9831e-01,  1.1757e+00, -1.6045e+00,  7.1296e-01,  1.1534e+00,\n",
       "          -1.5284e-01, -1.0722e+00, -1.4576e-01],\n",
       "         [ 6.4363e-01, -6.3906e-01,  1.1808e+00, -1.0513e+00, -1.4415e+00,\n",
       "           4.8274e-01, -3.3263e-02,  1.6257e+00],\n",
       "         [ 1.5440e-01,  5.2303e-01,  8.9328e-01, -7.3164e-01, -3.1596e-01,\n",
       "           4.0296e-01,  7.9414e-01, -2.2564e-01],\n",
       "         [-3.7523e-01,  8.9464e-01, -6.4019e-01, -5.4279e-01,  2.5829e-01,\n",
       "          -3.6608e-01,  3.6291e-01, -2.9527e-01],\n",
       "         [ 3.3257e-01,  5.3736e-01, -4.9683e-01, -2.5967e-01, -5.6160e-02,\n",
       "           6.9653e-02,  8.5621e-01,  1.4704e-01],\n",
       "         [-9.3185e-01, -1.1369e+00,  1.4449e-01,  1.5351e-01, -1.4387e+00,\n",
       "          -1.0545e+00,  2.1240e+00, -2.0757e-01],\n",
       "         [-1.3540e+00,  1.2932e+00,  6.4450e-01,  1.1437e-02,  1.8367e+00,\n",
       "           5.0792e-01, -4.4783e-01,  1.0773e+00],\n",
       "         [ 6.6068e-01, -2.2530e+00, -6.4972e-01,  1.2993e-01,  6.1931e-02,\n",
       "           6.0985e-01,  2.7827e-01, -3.6852e-01],\n",
       "         [-2.4046e-01, -1.8752e+00, -3.8571e-01, -8.0565e-01,  6.4884e-02,\n",
       "           4.7604e-01,  2.6321e-01, -6.0960e-02],\n",
       "         [-2.1798e+00, -1.2236e+00, -7.7747e-01, -1.4045e-01, -3.3429e-01,\n",
       "          -1.0405e+00,  9.8547e-01, -6.9524e-01],\n",
       "         [-1.5904e+00, -9.7195e-01,  1.6743e+00,  1.0130e+00, -7.8146e-02,\n",
       "           3.6116e+00,  1.4920e+00, -6.8089e-01],\n",
       "         [ 6.3482e-01,  3.1098e-01, -6.5810e-01, -1.1323e+00, -6.1610e-02,\n",
       "          -9.7491e-01, -1.1639e-01, -1.1711e+00],\n",
       "         [-9.2120e-02,  1.1335e+00,  6.3976e-01,  5.4550e-02, -5.6843e-01,\n",
       "          -5.2301e-01, -7.6853e-01, -2.7734e+00],\n",
       "         [ 4.0397e-01,  5.2337e-01, -7.9743e-02, -1.0107e+00,  5.1138e-01,\n",
       "          -5.4751e-01,  1.1063e+00, -6.3442e-01],\n",
       "         [ 5.9596e-01,  2.2613e+00, -9.1371e-01, -3.1046e-01,  1.3515e+00,\n",
       "           1.0481e+00,  9.6759e-02,  1.0964e+00],\n",
       "         [ 1.0933e+00,  6.7187e-01,  4.9410e-02,  7.7413e-01,  1.9874e-01,\n",
       "          -1.2197e-01, -6.3700e-01, -3.0957e-01],\n",
       "         [ 8.9707e-01,  8.0145e-01, -8.5023e-01, -7.6270e-01,  5.8708e-01,\n",
       "           6.6166e-01,  1.0190e+00, -7.6326e-01],\n",
       "         [-7.0507e-01, -4.0814e-01, -4.8129e-01, -1.3216e+00, -3.9846e-01,\n",
       "           4.4371e-01,  3.1568e-01,  8.8805e-01],\n",
       "         [-5.6537e-01,  1.0063e+00,  7.9643e-01,  1.1114e+00,  7.0424e-01,\n",
       "          -1.2468e+00,  1.1124e+00,  7.2923e-01],\n",
       "         [ 4.6212e-01, -4.5084e-01, -3.7471e-01, -7.9844e-01, -1.2719e-02,\n",
       "          -1.1065e+00, -8.5898e-01, -7.3661e-01],\n",
       "         [ 5.8084e-01, -1.5883e-01,  1.2960e+00, -7.0458e-01,  1.2370e+00,\n",
       "           1.1349e-01, -7.9318e-01, -6.4473e-02],\n",
       "         [ 1.4759e+00,  3.0356e-01, -6.3970e-01,  7.8751e-01,  1.3924e+00,\n",
       "          -2.3261e+00, -6.5426e-02, -5.3609e-01],\n",
       "         [-1.1387e+00, -1.8758e+00,  1.0895e+00, -7.4520e-01, -5.2412e-01,\n",
       "           3.5047e-01,  1.3005e+00,  8.9138e-01],\n",
       "         [ 8.3848e-01,  1.3416e-01, -9.7521e-01, -8.7291e-01,  4.9346e-01,\n",
       "           1.8728e-01, -2.5540e-01,  2.3460e-01],\n",
       "         [ 6.5283e-02,  2.4059e+00,  1.6660e+00,  5.6473e-01,  7.4367e-01,\n",
       "          -1.2743e+00,  9.5548e-01,  4.4850e-02],\n",
       "         [ 1.4221e-01, -4.0867e-01, -1.1504e+00,  7.4318e-01, -3.2540e+00,\n",
       "          -6.2207e-01, -2.6981e-01, -9.7117e-01],\n",
       "         [ 9.2301e-01, -1.3952e+00, -2.0968e-01,  3.0487e-01,  1.8731e-02,\n",
       "          -2.5085e-01,  8.5893e-02, -9.0963e-01],\n",
       "         [ 1.4316e+00, -1.1610e+00,  1.7157e-01, -5.2762e-01,  1.1904e+00,\n",
       "          -2.1212e-01, -1.9056e-01, -1.4921e+00],\n",
       "         [-1.1806e-01, -1.2728e-01, -2.3908e+00,  2.0369e-01,  3.9106e-01,\n",
       "          -2.6068e-01,  6.7993e-01,  1.6229e+00],\n",
       "         [ 1.7086e+00,  7.8603e-01, -7.8935e-01, -5.8436e-01,  1.1351e+00,\n",
       "           9.1763e-01,  2.4942e+00, -3.4302e-01],\n",
       "         [-1.3972e+00,  1.8618e+00, -3.7060e-01,  5.8168e-01,  3.0032e-01,\n",
       "          -1.5628e+00, -3.0675e-01, -1.1656e+00],\n",
       "         [-1.8572e-01,  6.4405e-01, -1.0928e+00,  8.3705e-01,  6.2115e-01,\n",
       "           4.6932e-02, -4.9352e-01, -2.7533e+00],\n",
       "         [-1.5324e+00, -3.4633e-01, -2.3593e-02,  3.8077e-01,  5.8825e-01,\n",
       "           1.5256e-01, -4.4697e-01, -5.6332e-01],\n",
       "         [-1.9512e+00, -2.3622e-01,  1.0221e+00, -2.0192e-02, -2.9283e-01,\n",
       "          -2.6334e-01,  3.4002e-01, -5.3362e-01],\n",
       "         [-1.1877e+00,  1.1302e+00,  1.6472e+00, -3.2006e-01, -3.7311e-01,\n",
       "          -5.0760e-01,  3.7279e-01, -3.7996e-01],\n",
       "         [ 4.9488e-01, -1.5153e-01,  3.3790e-01, -3.4644e-01, -8.3034e-01,\n",
       "           1.8113e+00,  2.3075e+00,  1.1084e+00],\n",
       "         [-3.3658e-01,  1.6880e+00, -1.6649e-01,  3.3247e-01, -6.6721e-01,\n",
       "          -5.7668e-01,  2.4576e-01, -2.0609e+00],\n",
       "         [-1.5045e-01, -2.3447e-02,  1.0245e+00,  5.5573e-01, -2.2884e-01,\n",
       "          -8.6721e-01,  3.6386e-01,  7.7505e-03],\n",
       "         [-1.9919e-01, -3.4342e-01, -5.8194e-01, -3.1352e-01, -3.7067e-01,\n",
       "           1.3353e+00,  3.5958e-01, -2.8001e+00],\n",
       "         [-2.2196e-01,  1.0292e+00, -5.6256e-01,  1.9058e-02, -3.2095e-02,\n",
       "          -3.5295e-01, -7.3729e-01, -1.0369e+00],\n",
       "         [ 9.1158e-01,  3.2473e-02, -2.0834e-01,  3.4336e-02,  1.7622e+00,\n",
       "          -6.0292e-01,  3.6719e-01,  8.3261e-01],\n",
       "         [-3.8394e-01,  7.2112e-01, -4.7990e-01, -1.4521e-01, -2.1831e-01,\n",
       "           4.4421e-01,  1.4140e+00,  3.8068e-03],\n",
       "         [ 1.2173e+00,  1.1820e+00, -2.7401e-01, -4.1506e-01,  2.2620e-01,\n",
       "           1.0742e+00, -1.2245e+00,  2.1643e-01],\n",
       "         [ 4.8215e-01,  7.3543e-01,  1.1315e+00,  8.1568e-01,  5.9954e-01,\n",
       "          -1.7102e-01, -1.8648e-01, -6.5947e-01],\n",
       "         [-2.4001e+00, -3.7210e-03,  7.5395e-01, -8.6429e-01, -2.1212e+00,\n",
       "          -7.1503e-01, -2.5227e-01,  1.0481e+00],\n",
       "         [-1.4957e+00,  8.1987e-01, -9.2583e-01, -7.9617e-01,  1.1887e+00,\n",
       "           8.7211e-01, -2.1343e-01,  1.5238e-01],\n",
       "         [-1.4201e+00, -2.7263e-01, -1.5270e+00,  1.2872e-01, -6.8216e-02,\n",
       "           1.5087e+00,  8.0927e-02,  1.8625e+00],\n",
       "         [ 1.8070e+00,  2.3206e+00, -7.9625e-02,  1.1310e-01,  1.6548e+00,\n",
       "           4.9926e-01, -1.3917e+00,  5.2113e-01],\n",
       "         [-8.9994e-01,  8.4056e-01,  7.7325e-01,  4.6291e-01,  1.6175e+00,\n",
       "          -6.9149e-02, -1.8572e+00,  5.0700e-01],\n",
       "         [-5.8067e-02, -1.3031e-01,  1.2129e+00, -5.2559e-01, -7.2092e-02,\n",
       "          -1.1201e+00, -1.5440e+00, -4.9161e-02],\n",
       "         [-1.1774e+00,  1.0212e+00,  1.2643e+00,  4.5906e-01,  8.7048e-01,\n",
       "          -2.9071e-01, -5.8590e-01, -1.1510e+00],\n",
       "         [ 1.4728e-01, -2.7323e-01,  8.1339e-01, -1.9406e+00, -5.1971e-02,\n",
       "           4.0210e-01,  2.2295e-01, -6.5376e-01],\n",
       "         [ 1.1881e+00, -1.8582e+00,  1.6079e-02,  2.5692e-01,  3.8209e-01,\n",
       "           2.8877e-01,  8.6816e-01, -1.3836e-01],\n",
       "         [-5.5018e-01, -7.8309e-01,  8.0284e-02, -1.3963e-01,  8.0242e-01,\n",
       "           1.3236e-01, -6.3614e-01, -2.1576e-01],\n",
       "         [-1.0549e+00, -4.1905e-01, -1.5201e+00, -1.0895e+00,  7.2645e-01,\n",
       "          -4.0968e-01,  2.2721e-01, -1.2301e+00]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.4430,  0.4610, -0.0416,  0.3446,  0.0290,  0.1442,  0.0288,  0.3734],\n",
       "         [-0.0638,  0.0637,  0.0689, -0.1352,  0.1082, -0.4173, -0.0643, -0.2800],\n",
       "         [-0.0699,  0.6350,  0.5074, -0.2240, -0.6225,  0.0943, -0.4183,  0.1928],\n",
       "         [ 0.5491,  0.1094,  0.1913, -0.2462,  0.1621, -0.2340,  0.1737, -0.4644],\n",
       "         [-0.1655,  0.0444,  0.0723, -0.0875, -0.1893,  0.0249, -0.2375, -0.4282],\n",
       "         [ 0.5501,  0.6300,  0.3780, -0.0863,  0.0138,  0.1452, -0.0719,  0.4255],\n",
       "         [-0.1257,  0.1430, -0.2062, -0.0939,  0.4127,  0.0621, -0.5486,  0.1829],\n",
       "         [-0.1533, -0.0594, -0.5005,  0.2020,  0.1735, -0.5303,  0.0948, -0.1869],\n",
       "         [ 0.5190, -0.1083, -0.2712,  0.2632, -0.2597,  0.2143,  0.1134, -0.0493],\n",
       "         [ 0.3096,  0.5013, -0.1158,  0.1154, -0.2388, -0.0223, -0.2477,  0.4838],\n",
       "         [ 0.1100,  0.2135, -0.2168, -0.2018, -0.5393, -0.3089,  0.3356,  0.1205],\n",
       "         [ 0.1883,  0.0792,  0.1165, -0.2340, -0.3577, -0.0766, -0.4436,  0.1845],\n",
       "         [ 0.0457,  0.3721,  0.1245,  0.2324,  0.0945, -0.1850,  0.1471, -0.4871],\n",
       "         [ 0.1079,  0.0400, -0.2345, -0.3591, -0.1827, -0.4794, -0.2797, -0.0692],\n",
       "         [-0.1292,  0.0737,  0.0494,  0.0334, -0.2895,  0.0370,  0.4048,  0.4866],\n",
       "         [ 0.3899,  0.3307,  0.0035, -0.1211,  0.1731, -0.1046, -0.3503, -0.1976],\n",
       "         [-0.2137,  0.1301,  0.0573,  0.1343,  0.3958, -0.4048, -0.3428,  0.2740],\n",
       "         [ 0.1169, -0.4258, -0.1516, -0.2867, -0.2844,  0.5667,  0.3900,  0.4789]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 2.4423e-01,  2.9958e-01,  1.4053e-02,  2.1357e-01,  1.8280e-01,\n",
       "          -6.5205e-01],\n",
       "         [ 5.3494e-01,  1.2163e-01, -5.1683e-01, -1.9028e-01,  2.6529e-01,\n",
       "          -3.6566e-01],\n",
       "         [ 5.8340e-01,  1.5779e-01, -2.3191e-01,  4.0989e-01,  3.7934e-01,\n",
       "          -3.5694e-01],\n",
       "         [ 3.1087e-01, -4.1615e-01, -1.6748e-01, -3.4839e-01, -3.2701e-01,\n",
       "           3.3188e-04],\n",
       "         [ 9.5991e-02, -9.2908e-03, -8.3929e-02, -1.2903e-01,  1.8965e-01,\n",
       "          -6.2272e-01],\n",
       "         [-1.0208e-04,  8.5063e-02, -5.8061e-01, -1.1890e-01,  4.5717e-02,\n",
       "          -6.4968e-02],\n",
       "         [ 2.1910e-02,  4.1060e-01, -1.2763e-01,  3.1607e-01, -2.4030e-01,\n",
       "          -2.6209e-01],\n",
       "         [-1.2527e-01,  2.5001e-02,  1.1144e-01, -7.7491e-02, -2.5837e-01,\n",
       "           5.2915e-02],\n",
       "         [ 3.9345e-01, -3.9332e-01,  1.8513e-01,  3.2425e-01, -1.8171e-01,\n",
       "          -3.9737e-01],\n",
       "         [-1.6671e-01, -1.5129e-01,  2.2860e-01, -2.8841e-01, -2.7854e-01,\n",
       "           1.7533e-01],\n",
       "         [-3.9242e-01,  3.3338e-01, -2.7045e-03, -1.7896e-01, -2.8595e-01,\n",
       "           2.0569e-01],\n",
       "         [-4.3710e-01,  2.4333e-02,  4.3465e-01, -6.8678e-02,  1.5308e-01,\n",
       "          -3.0786e-02],\n",
       "         [-1.1015e-01, -2.3258e-01, -4.5734e-01,  4.0111e-01,  3.8311e-01,\n",
       "          -4.9813e-01],\n",
       "         [-1.2845e-01, -8.3008e-02, -1.0367e-01,  3.2598e-01, -1.0302e-01,\n",
       "          -5.0452e-01],\n",
       "         [-4.9384e-01,  2.6097e-02,  1.0604e-01,  2.6408e-02, -1.4664e-02,\n",
       "           5.9804e-01],\n",
       "         [-2.6828e-01,  4.6911e-01,  1.1602e-01,  4.3001e-01,  3.9529e-01,\n",
       "          -3.9152e-01],\n",
       "         [ 4.7049e-02, -1.6204e-02, -1.9531e-01,  4.7477e-01, -3.1309e-01,\n",
       "          -3.5865e-01],\n",
       "         [-1.2379e-01, -2.8360e-01, -2.3780e-02,  1.0367e-02, -4.6945e-01,\n",
       "           6.5767e-01]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.3802, -0.1510,  0.2599, -0.1580,  0.3886, -0.2115,  0.0935,  0.0279,\n",
       "         -0.2702,  0.1405, -0.2824, -0.0884,  0.0638, -0.1071, -0.2700,  0.3823,\n",
       "         -0.2518, -0.0887], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0814,  0.1380,  0.4819,  0.0271, -0.1774, -0.1490,  0.0651,  0.3317,\n",
       "         -0.2520, -0.0738, -0.0500, -0.2695,  0.3897,  0.3761, -0.1588,  0.1587,\n",
       "          0.3699, -0.4247], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.4155,  0.3399, -0.5908,  0.4130,  0.1879, -0.3860],\n",
       "         [-0.2242,  0.1846, -0.1200, -0.0764, -0.0632,  0.2742]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.0330, 0.2645], requires_grad=True)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가중치 확인\n",
    "list(simple_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding: torch.Size([60, 8]) \n",
      " GRU:  torch.Size([18, 8]) \n",
      " torch.Size([18, 6]) torch.Size([18]) torch.Size([18]) \n",
      " Linear regression :  torch.Size([2, 6]) \n",
      " torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "para = list(simple_model.parameters())\n",
    "print('Embedding:', para[0].shape,'\\n GRU: ', para[1].shape,\n",
    "      '\\n', para[2].shape, para[3].shape, para[4].shape,\n",
    "       '\\n Linear regression : ', para[5].shape,'\\n', para[6].shape)\n",
    "# Model 가중치에는 총 7개 요소가 있으며, 앞서 확인한 \n",
    "# Embedding, RNN, Linear regression 등의 가중치가 모두 포함되었음을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60, 8]) tensor([[ 3.0864e-01,  9.8647e-01,  1.3314e+00, -5.8387e-01, -5.3893e-01,\n",
      "          8.6339e-02, -7.3325e-01,  1.2195e+00],\n",
      "        [ 7.5774e-01,  1.4066e+00,  4.3821e-01, -6.8423e-01, -4.2995e-01,\n",
      "         -9.5826e-01, -4.1490e-02, -1.4533e+00],\n",
      "        [-1.0715e-01,  9.2046e-01,  1.2394e+00, -8.8895e-04, -1.5224e+00,\n",
      "         -1.9200e-01,  3.9307e-01, -7.6895e-01],\n",
      "        [ 8.7640e-01,  6.1190e-02, -1.7413e-01,  1.4305e+00, -3.4882e-01,\n",
      "         -1.0501e+00, -1.4155e-01, -1.0586e-02],\n",
      "        [ 5.7630e-01,  3.7684e-01, -1.0586e+00,  3.8520e-01,  7.5463e-02,\n",
      "         -7.8259e-01, -8.2497e-01,  2.1316e-01],\n",
      "        [ 7.9831e-01,  1.1757e+00, -1.6045e+00,  7.1296e-01,  1.1534e+00,\n",
      "         -1.5284e-01, -1.0722e+00, -1.4576e-01],\n",
      "        [ 6.4363e-01, -6.3906e-01,  1.1808e+00, -1.0513e+00, -1.4415e+00,\n",
      "          4.8274e-01, -3.3263e-02,  1.6257e+00],\n",
      "        [ 1.5440e-01,  5.2303e-01,  8.9328e-01, -7.3164e-01, -3.1596e-01,\n",
      "          4.0296e-01,  7.9414e-01, -2.2564e-01],\n",
      "        [-3.7523e-01,  8.9464e-01, -6.4019e-01, -5.4279e-01,  2.5829e-01,\n",
      "         -3.6608e-01,  3.6291e-01, -2.9527e-01],\n",
      "        [ 3.3257e-01,  5.3736e-01, -4.9683e-01, -2.5967e-01, -5.6160e-02,\n",
      "          6.9653e-02,  8.5621e-01,  1.4704e-01],\n",
      "        [-9.3185e-01, -1.1369e+00,  1.4449e-01,  1.5351e-01, -1.4387e+00,\n",
      "         -1.0545e+00,  2.1240e+00, -2.0757e-01],\n",
      "        [-1.3540e+00,  1.2932e+00,  6.4450e-01,  1.1437e-02,  1.8367e+00,\n",
      "          5.0792e-01, -4.4783e-01,  1.0773e+00],\n",
      "        [ 6.6068e-01, -2.2530e+00, -6.4972e-01,  1.2993e-01,  6.1931e-02,\n",
      "          6.0985e-01,  2.7827e-01, -3.6852e-01],\n",
      "        [-2.4046e-01, -1.8752e+00, -3.8571e-01, -8.0565e-01,  6.4884e-02,\n",
      "          4.7604e-01,  2.6321e-01, -6.0960e-02],\n",
      "        [-2.1798e+00, -1.2236e+00, -7.7747e-01, -1.4045e-01, -3.3429e-01,\n",
      "         -1.0405e+00,  9.8547e-01, -6.9524e-01],\n",
      "        [-1.5904e+00, -9.7195e-01,  1.6743e+00,  1.0130e+00, -7.8146e-02,\n",
      "          3.6116e+00,  1.4920e+00, -6.8089e-01],\n",
      "        [ 6.3482e-01,  3.1098e-01, -6.5810e-01, -1.1323e+00, -6.1610e-02,\n",
      "         -9.7491e-01, -1.1639e-01, -1.1711e+00],\n",
      "        [-9.2120e-02,  1.1335e+00,  6.3976e-01,  5.4550e-02, -5.6843e-01,\n",
      "         -5.2301e-01, -7.6853e-01, -2.7734e+00],\n",
      "        [ 4.0397e-01,  5.2337e-01, -7.9743e-02, -1.0107e+00,  5.1138e-01,\n",
      "         -5.4751e-01,  1.1063e+00, -6.3442e-01],\n",
      "        [ 5.9596e-01,  2.2613e+00, -9.1371e-01, -3.1046e-01,  1.3515e+00,\n",
      "          1.0481e+00,  9.6759e-02,  1.0964e+00],\n",
      "        [ 1.0933e+00,  6.7187e-01,  4.9410e-02,  7.7413e-01,  1.9874e-01,\n",
      "         -1.2197e-01, -6.3700e-01, -3.0957e-01],\n",
      "        [ 8.9707e-01,  8.0145e-01, -8.5023e-01, -7.6270e-01,  5.8708e-01,\n",
      "          6.6166e-01,  1.0190e+00, -7.6326e-01],\n",
      "        [-7.0507e-01, -4.0814e-01, -4.8129e-01, -1.3216e+00, -3.9846e-01,\n",
      "          4.4371e-01,  3.1568e-01,  8.8805e-01],\n",
      "        [-5.6537e-01,  1.0063e+00,  7.9643e-01,  1.1114e+00,  7.0424e-01,\n",
      "         -1.2468e+00,  1.1124e+00,  7.2923e-01],\n",
      "        [ 4.6212e-01, -4.5084e-01, -3.7471e-01, -7.9844e-01, -1.2719e-02,\n",
      "         -1.1065e+00, -8.5898e-01, -7.3661e-01],\n",
      "        [ 5.8084e-01, -1.5883e-01,  1.2960e+00, -7.0458e-01,  1.2370e+00,\n",
      "          1.1349e-01, -7.9318e-01, -6.4473e-02],\n",
      "        [ 1.4759e+00,  3.0356e-01, -6.3970e-01,  7.8751e-01,  1.3924e+00,\n",
      "         -2.3261e+00, -6.5426e-02, -5.3609e-01],\n",
      "        [-1.1387e+00, -1.8758e+00,  1.0895e+00, -7.4520e-01, -5.2412e-01,\n",
      "          3.5047e-01,  1.3005e+00,  8.9138e-01],\n",
      "        [ 8.3848e-01,  1.3416e-01, -9.7521e-01, -8.7291e-01,  4.9346e-01,\n",
      "          1.8728e-01, -2.5540e-01,  2.3460e-01],\n",
      "        [ 6.5283e-02,  2.4059e+00,  1.6660e+00,  5.6473e-01,  7.4367e-01,\n",
      "         -1.2743e+00,  9.5548e-01,  4.4850e-02],\n",
      "        [ 1.4221e-01, -4.0867e-01, -1.1504e+00,  7.4318e-01, -3.2540e+00,\n",
      "         -6.2207e-01, -2.6981e-01, -9.7117e-01],\n",
      "        [ 9.2301e-01, -1.3952e+00, -2.0968e-01,  3.0487e-01,  1.8731e-02,\n",
      "         -2.5085e-01,  8.5893e-02, -9.0963e-01],\n",
      "        [ 1.4316e+00, -1.1610e+00,  1.7157e-01, -5.2762e-01,  1.1904e+00,\n",
      "         -2.1212e-01, -1.9056e-01, -1.4921e+00],\n",
      "        [-1.1806e-01, -1.2728e-01, -2.3908e+00,  2.0369e-01,  3.9106e-01,\n",
      "         -2.6068e-01,  6.7993e-01,  1.6229e+00],\n",
      "        [ 1.7086e+00,  7.8603e-01, -7.8935e-01, -5.8436e-01,  1.1351e+00,\n",
      "          9.1763e-01,  2.4942e+00, -3.4302e-01],\n",
      "        [-1.3972e+00,  1.8618e+00, -3.7060e-01,  5.8168e-01,  3.0032e-01,\n",
      "         -1.5628e+00, -3.0675e-01, -1.1656e+00],\n",
      "        [-1.8572e-01,  6.4405e-01, -1.0928e+00,  8.3705e-01,  6.2115e-01,\n",
      "          4.6932e-02, -4.9352e-01, -2.7533e+00],\n",
      "        [-1.5324e+00, -3.4633e-01, -2.3593e-02,  3.8077e-01,  5.8825e-01,\n",
      "          1.5256e-01, -4.4697e-01, -5.6332e-01],\n",
      "        [-1.9512e+00, -2.3622e-01,  1.0221e+00, -2.0192e-02, -2.9283e-01,\n",
      "         -2.6334e-01,  3.4002e-01, -5.3362e-01],\n",
      "        [-1.1877e+00,  1.1302e+00,  1.6472e+00, -3.2006e-01, -3.7311e-01,\n",
      "         -5.0760e-01,  3.7279e-01, -3.7996e-01],\n",
      "        [ 4.9488e-01, -1.5153e-01,  3.3790e-01, -3.4644e-01, -8.3034e-01,\n",
      "          1.8113e+00,  2.3075e+00,  1.1084e+00],\n",
      "        [-3.3658e-01,  1.6880e+00, -1.6649e-01,  3.3247e-01, -6.6721e-01,\n",
      "         -5.7668e-01,  2.4576e-01, -2.0609e+00],\n",
      "        [-1.5045e-01, -2.3447e-02,  1.0245e+00,  5.5573e-01, -2.2884e-01,\n",
      "         -8.6721e-01,  3.6386e-01,  7.7505e-03],\n",
      "        [-1.9919e-01, -3.4342e-01, -5.8194e-01, -3.1352e-01, -3.7067e-01,\n",
      "          1.3353e+00,  3.5958e-01, -2.8001e+00],\n",
      "        [-2.2196e-01,  1.0292e+00, -5.6256e-01,  1.9058e-02, -3.2095e-02,\n",
      "         -3.5295e-01, -7.3729e-01, -1.0369e+00],\n",
      "        [ 9.1158e-01,  3.2473e-02, -2.0834e-01,  3.4336e-02,  1.7622e+00,\n",
      "         -6.0292e-01,  3.6719e-01,  8.3261e-01],\n",
      "        [-3.8394e-01,  7.2112e-01, -4.7990e-01, -1.4521e-01, -2.1831e-01,\n",
      "          4.4421e-01,  1.4140e+00,  3.8068e-03],\n",
      "        [ 1.2173e+00,  1.1820e+00, -2.7401e-01, -4.1506e-01,  2.2620e-01,\n",
      "          1.0742e+00, -1.2245e+00,  2.1643e-01],\n",
      "        [ 4.8215e-01,  7.3543e-01,  1.1315e+00,  8.1568e-01,  5.9954e-01,\n",
      "         -1.7102e-01, -1.8648e-01, -6.5947e-01],\n",
      "        [-2.4001e+00, -3.7210e-03,  7.5395e-01, -8.6429e-01, -2.1212e+00,\n",
      "         -7.1503e-01, -2.5227e-01,  1.0481e+00],\n",
      "        [-1.4957e+00,  8.1987e-01, -9.2583e-01, -7.9617e-01,  1.1887e+00,\n",
      "          8.7211e-01, -2.1343e-01,  1.5238e-01],\n",
      "        [-1.4201e+00, -2.7263e-01, -1.5270e+00,  1.2872e-01, -6.8216e-02,\n",
      "          1.5087e+00,  8.0927e-02,  1.8625e+00],\n",
      "        [ 1.8070e+00,  2.3206e+00, -7.9625e-02,  1.1310e-01,  1.6548e+00,\n",
      "          4.9926e-01, -1.3917e+00,  5.2113e-01],\n",
      "        [-8.9994e-01,  8.4056e-01,  7.7325e-01,  4.6291e-01,  1.6175e+00,\n",
      "         -6.9149e-02, -1.8572e+00,  5.0700e-01],\n",
      "        [-5.8067e-02, -1.3031e-01,  1.2129e+00, -5.2559e-01, -7.2092e-02,\n",
      "         -1.1201e+00, -1.5440e+00, -4.9161e-02],\n",
      "        [-1.1774e+00,  1.0212e+00,  1.2643e+00,  4.5906e-01,  8.7048e-01,\n",
      "         -2.9071e-01, -5.8590e-01, -1.1510e+00],\n",
      "        [ 1.4728e-01, -2.7323e-01,  8.1339e-01, -1.9406e+00, -5.1971e-02,\n",
      "          4.0210e-01,  2.2295e-01, -6.5376e-01],\n",
      "        [ 1.1881e+00, -1.8582e+00,  1.6079e-02,  2.5692e-01,  3.8209e-01,\n",
      "          2.8877e-01,  8.6816e-01, -1.3836e-01],\n",
      "        [-5.5018e-01, -7.8309e-01,  8.0284e-02, -1.3963e-01,  8.0242e-01,\n",
      "          1.3236e-01, -6.3614e-01, -2.1576e-01],\n",
      "        [-1.0549e+00, -4.1905e-01, -1.5201e+00, -1.0895e+00,  7.2645e-01,\n",
      "         -4.0968e-01,  2.2721e-01, -1.2301e+00]])\n"
     ]
    }
   ],
   "source": [
    "# 가중치인 generator 동작 확인\n",
    "para = next(simple_model.parameters()).data\n",
    "print(para.shape,para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.5210e-01,  5.2201e-01,  8.9225e-01, -7.3292e-01],\n",
       "         [-3.1660e-01,  4.0322e-01,  7.9435e-01, -2.2512e-01],\n",
       "         [-9.2847e-01, -1.1346e+00,  1.4568e-01,  1.5525e-01],\n",
       "         [-1.4372e+00, -1.0565e+00,  2.1219e+00, -2.0955e-01],\n",
       "         [ 3.0701e-01,  9.8639e-01,  1.3318e+00, -5.8268e-01]],\n",
       "\n",
       "        [[-5.3861e-01,  8.6189e-02, -7.3272e-01,  1.2194e+00],\n",
       "         [ 7.9899e-01,  1.1753e+00, -1.6056e+00,  7.1290e-01],\n",
       "         [ 1.1527e+00, -1.5229e-01, -1.0714e+00, -1.4513e-01],\n",
       "         [-3.7647e-01,  8.9324e-01, -6.4132e-01, -5.4362e-01],\n",
       "         [ 2.5706e-01, -3.6503e-01,  3.6410e-01, -2.9418e-01]],\n",
       "\n",
       "        [[ 3.0701e-01,  9.8639e-01,  1.3318e+00, -5.8268e-01],\n",
       "         [-5.3861e-01,  8.6189e-02, -7.3272e-01,  1.2194e+00],\n",
       "         [ 1.5210e-01,  5.2201e-01,  8.9225e-01, -7.3292e-01],\n",
       "         [-3.1660e-01,  4.0322e-01,  7.9435e-01, -2.2512e-01],\n",
       "         [ 5.7616e-01,  3.7601e-01, -1.0595e+00,  3.8459e-01]],\n",
       "\n",
       "        [[ 7.4630e-02, -7.8198e-01, -8.2447e-01,  2.1436e-01],\n",
       "         [ 3.0701e-01,  9.8639e-01,  1.3318e+00, -5.8268e-01],\n",
       "         [-5.3861e-01,  8.6189e-02, -7.3272e-01,  1.2194e+00],\n",
       "         [-9.2352e-02,  1.1335e+00,  6.3972e-01,  5.4372e-02],\n",
       "         [-5.6847e-01, -5.2305e-01, -7.6914e-01, -2.7728e+00]],\n",
       "\n",
       "        [[ 1.8082e+00,  2.3204e+00, -8.1563e-02,  1.1125e-01],\n",
       "         [ 1.6536e+00,  4.9937e-01, -1.3928e+00,  5.2226e-01],\n",
       "         [ 3.0701e-01,  9.8639e-01,  1.3318e+00, -5.8268e-01],\n",
       "         [-5.3861e-01,  8.6189e-02, -7.3272e-01,  1.2194e+00],\n",
       "         [-5.5451e-01, -7.8678e-01,  7.7049e-02, -1.4319e-01]],\n",
       "\n",
       "        [[ 7.9892e-01,  1.3548e-01, -6.3320e-01, -2.1219e-01],\n",
       "         [ 3.0701e-01,  9.8639e-01,  1.3318e+00, -5.8268e-01],\n",
       "         [-5.3861e-01,  8.6189e-02, -7.3272e-01,  1.2194e+00],\n",
       "         [ 7.9899e-01,  1.1753e+00, -1.6056e+00,  7.1290e-01],\n",
       "         [ 1.1527e+00, -1.5229e-01, -1.0714e+00, -1.4513e-01]],\n",
       "\n",
       "        [[ 3.0701e-01,  9.8639e-01,  1.3318e+00, -5.8268e-01],\n",
       "         [-5.3861e-01,  8.6189e-02, -7.3272e-01,  1.2194e+00],\n",
       "         [ 7.9899e-01,  1.1753e+00, -1.6056e+00,  7.1290e-01],\n",
       "         [ 1.1527e+00, -1.5229e-01, -1.0714e+00, -1.4513e-01],\n",
       "         [ 3.0701e-01,  9.8639e-01,  1.3318e+00, -5.8268e-01]],\n",
       "\n",
       "        [[-5.3861e-01,  8.6189e-02, -7.3272e-01,  1.2194e+00],\n",
       "         [ 3.0701e-01,  9.8639e-01,  1.3318e+00, -5.8268e-01],\n",
       "         [-5.3861e-01,  8.6189e-02, -7.3272e-01,  1.2194e+00],\n",
       "         [ 3.0701e-01,  9.8639e-01,  1.3318e+00, -5.8268e-01],\n",
       "         [-5.3861e-01,  8.6189e-02, -7.3272e-01,  1.2194e+00]],\n",
       "\n",
       "        [[ 5.9644e-01,  2.2606e+00, -9.1434e-01, -3.1116e-01],\n",
       "         [ 1.3507e+00,  1.0487e+00,  9.7370e-02,  1.0971e+00],\n",
       "         [-1.9936e-01, -3.4392e-01, -5.8219e-01, -3.1373e-01],\n",
       "         [-3.7074e-01,  1.3355e+00,  3.5952e-01, -2.7996e+00],\n",
       "         [ 7.9899e-01,  1.1753e+00, -1.6056e+00,  7.1290e-01]],\n",
       "\n",
       "        [[ 1.1527e+00, -1.5229e-01, -1.0714e+00, -1.4513e-01],\n",
       "         [ 3.0701e-01,  9.8639e-01,  1.3318e+00, -5.8268e-01],\n",
       "         [-5.3861e-01,  8.6189e-02, -7.3272e-01,  1.2194e+00],\n",
       "         [ 8.7559e-01,  6.0052e-02, -1.7545e-01,  1.4300e+00],\n",
       "         [-3.4963e-01, -1.0491e+00, -1.4039e-01, -9.6880e-03]],\n",
       "\n",
       "        [[ 1.1859e+00, -1.8609e+00,  1.3660e-02,  2.5705e-01],\n",
       "         [ 3.7918e-01,  2.9154e-01,  8.7058e-01, -1.3576e-01],\n",
       "         [-3.3658e-01,  1.6870e+00, -1.6679e-01,  3.3179e-01],\n",
       "         [-6.6903e-01, -5.7569e-01,  2.4660e-01, -2.0595e+00],\n",
       "         [ 5.7616e-01,  3.7601e-01, -1.0595e+00,  3.8459e-01]],\n",
       "\n",
       "        [[ 7.4630e-02, -7.8198e-01, -8.2447e-01,  2.1436e-01],\n",
       "         [ 3.0701e-01,  9.8639e-01,  1.3318e+00, -5.8268e-01],\n",
       "         [-5.3861e-01,  8.6189e-02, -7.3272e-01,  1.2194e+00],\n",
       "         [-3.7647e-01,  8.9324e-01, -6.4132e-01, -5.4362e-01],\n",
       "         [ 2.5706e-01, -3.6503e-01,  3.6410e-01, -2.9418e-01]],\n",
       "\n",
       "        [[ 3.0701e-01,  9.8639e-01,  1.3318e+00, -5.8268e-01],\n",
       "         [-5.3861e-01,  8.6189e-02, -7.3272e-01,  1.2194e+00],\n",
       "         [ 1.5210e-01,  5.2201e-01,  8.9225e-01, -7.3292e-01],\n",
       "         [-3.1660e-01,  4.0322e-01,  7.9435e-01, -2.2512e-01],\n",
       "         [ 3.0701e-01,  9.8639e-01,  1.3318e+00, -5.8268e-01]],\n",
       "\n",
       "        [[-5.3861e-01,  8.6189e-02, -7.3272e-01,  1.2194e+00],\n",
       "         [ 3.0701e-01,  9.8639e-01,  1.3318e+00, -5.8268e-01],\n",
       "         [-5.3861e-01,  8.6189e-02, -7.3272e-01,  1.2194e+00],\n",
       "         [ 7.9899e-01,  1.1753e+00, -1.6056e+00,  7.1290e-01],\n",
       "         [ 1.1527e+00, -1.5229e-01, -1.0714e+00, -1.4513e-01]],\n",
       "\n",
       "        [[ 3.0701e-01,  9.8639e-01,  1.3318e+00, -5.8268e-01],\n",
       "         [-5.3861e-01,  8.6189e-02, -7.3272e-01,  1.2194e+00],\n",
       "         [-3.7647e-01,  8.9324e-01, -6.4132e-01, -5.4362e-01],\n",
       "         [ 2.5706e-01, -3.6503e-01,  3.6410e-01, -2.9418e-01],\n",
       "         [ 3.0701e-01,  9.8639e-01,  1.3318e+00, -5.8268e-01]],\n",
       "\n",
       "        [[-5.3861e-01,  8.6189e-02, -7.3272e-01,  1.2194e+00],\n",
       "         [ 5.7616e-01,  3.7601e-01, -1.0595e+00,  3.8459e-01],\n",
       "         [ 7.4630e-02, -7.8198e-01, -8.2447e-01,  2.1436e-01],\n",
       "         [ 3.0701e-01,  9.8639e-01,  1.3318e+00, -5.8268e-01],\n",
       "         [-5.3861e-01,  8.6189e-02, -7.3272e-01,  1.2194e+00]],\n",
       "\n",
       "        [[ 1.1859e+00, -1.8609e+00,  1.3660e-02,  2.5705e-01],\n",
       "         [ 3.7918e-01,  2.9154e-01,  8.7058e-01, -1.3576e-01],\n",
       "         [-3.3658e-01,  1.6870e+00, -1.6679e-01,  3.3179e-01],\n",
       "         [-6.6903e-01, -5.7569e-01,  2.4660e-01, -2.0595e+00],\n",
       "         [ 3.0701e-01,  9.8639e-01,  1.3318e+00, -5.8268e-01]],\n",
       "\n",
       "        [[-5.3861e-01,  8.6189e-02, -7.3272e-01,  1.2194e+00],\n",
       "         [-1.0982e-01,  9.1962e-01,  1.2383e+00, -1.4587e-03],\n",
       "         [-1.5227e+00, -1.9156e-01,  3.9324e-01, -7.6799e-01],\n",
       "         [-1.9521e+00, -2.3674e-01,  1.0215e+00, -2.0262e-02],\n",
       "         [-2.9320e-01, -2.6278e-01,  3.4071e-01, -5.3347e-01]],\n",
       "\n",
       "        [[ 3.0701e-01,  9.8639e-01,  1.3318e+00, -5.8268e-01],\n",
       "         [-5.3861e-01,  8.6189e-02, -7.3272e-01,  1.2194e+00],\n",
       "         [ 3.0701e-01,  9.8639e-01,  1.3318e+00, -5.8268e-01],\n",
       "         [-5.3861e-01,  8.6189e-02, -7.3272e-01,  1.2194e+00],\n",
       "         [-2.3886e-01, -1.8736e+00, -3.8411e-01, -8.0405e-01]],\n",
       "\n",
       "        [[ 6.6499e-02,  4.7444e-01,  2.6161e-01, -6.2589e-02],\n",
       "         [ 3.0701e-01,  9.8639e-01,  1.3318e+00, -5.8268e-01],\n",
       "         [-5.3861e-01,  8.6189e-02, -7.3272e-01,  1.2194e+00],\n",
       "         [ 3.0701e-01,  9.8639e-01,  1.3318e+00, -5.8268e-01],\n",
       "         [-5.3861e-01,  8.6189e-02, -7.3272e-01,  1.2194e+00]],\n",
       "\n",
       "        [[ 7.9899e-01,  1.1753e+00, -1.6056e+00,  7.1290e-01],\n",
       "         [ 1.1527e+00, -1.5229e-01, -1.0714e+00, -1.4513e-01],\n",
       "         [ 3.0701e-01,  9.8639e-01,  1.3318e+00, -5.8268e-01],\n",
       "         [-5.3861e-01,  8.6189e-02, -7.3272e-01,  1.2194e+00],\n",
       "         [ 8.9831e-01,  8.0302e-01, -8.4874e-01, -7.6126e-01]],\n",
       "\n",
       "        [[ 5.8870e-01,  6.6010e-01,  1.0173e+00, -7.6476e-01],\n",
       "         [-1.4185e+00, -2.7101e-01, -1.5253e+00,  1.3032e-01],\n",
       "         [-6.6619e-02,  1.5071e+00,  7.9304e-02,  1.8609e+00],\n",
       "         [ 3.0701e-01,  9.8639e-01,  1.3318e+00, -5.8268e-01],\n",
       "         [-5.3861e-01,  8.6189e-02, -7.3272e-01,  1.2194e+00]],\n",
       "\n",
       "        [[-2.3886e-01, -1.8736e+00, -3.8411e-01, -8.0405e-01],\n",
       "         [ 6.6499e-02,  4.7444e-01,  2.6161e-01, -6.2589e-02],\n",
       "         [ 5.8022e-01, -1.5921e-01,  1.2958e+00, -7.0443e-01],\n",
       "         [ 1.2370e+00,  1.1369e-01, -7.9282e-01, -6.4432e-02],\n",
       "         [ 3.0701e-01,  9.8639e-01,  1.3318e+00, -5.8268e-01]],\n",
       "\n",
       "        [[-5.3861e-01,  8.6189e-02, -7.3272e-01,  1.2194e+00],\n",
       "         [ 3.0701e-01,  9.8639e-01,  1.3318e+00, -5.8268e-01],\n",
       "         [-5.3861e-01,  8.6189e-02, -7.3272e-01,  1.2194e+00],\n",
       "         [ 3.0701e-01,  9.8639e-01,  1.3318e+00, -5.8268e-01],\n",
       "         [-5.3861e-01,  8.6189e-02, -7.3272e-01,  1.2194e+00]],\n",
       "\n",
       "        [[-2.2255e-01,  1.0299e+00, -5.6122e-01,  1.9486e-02],\n",
       "         [-3.1795e-02, -3.5404e-01, -7.3568e-01, -1.0376e+00],\n",
       "         [-9.2352e-02,  1.1335e+00,  6.3972e-01,  5.4372e-02],\n",
       "         [-5.6847e-01, -5.2305e-01, -7.6914e-01, -2.7728e+00],\n",
       "         [ 1.4887e-01, -2.7157e-01,  8.1505e-01, -1.9389e+00]],\n",
       "\n",
       "        [[-5.0316e-02,  4.0044e-01,  2.2129e-01, -6.5542e-01],\n",
       "         [-2.1785e+00, -1.2222e+00, -7.7601e-01, -1.3902e-01],\n",
       "         [-3.3279e-01, -1.0420e+00,  9.8392e-01, -6.9672e-01],\n",
       "         [ 3.0701e-01,  9.8639e-01,  1.3318e+00, -5.8268e-01],\n",
       "         [-5.3861e-01,  8.6189e-02, -7.3272e-01,  1.2194e+00]],\n",
       "\n",
       "        [[ 3.0701e-01,  9.8639e-01,  1.3318e+00, -5.8268e-01],\n",
       "         [-5.3861e-01,  8.6189e-02, -7.3272e-01,  1.2194e+00],\n",
       "         [ 3.0701e-01,  9.8639e-01,  1.3318e+00, -5.8268e-01],\n",
       "         [-5.3861e-01,  8.6189e-02, -7.3272e-01,  1.2194e+00],\n",
       "         [ 3.0701e-01,  9.8639e-01,  1.3318e+00, -5.8268e-01]],\n",
       "\n",
       "        [[-5.3861e-01,  8.6189e-02, -7.3272e-01,  1.2194e+00],\n",
       "         [ 3.0701e-01,  9.8639e-01,  1.3318e+00, -5.8268e-01],\n",
       "         [-5.3861e-01,  8.6189e-02, -7.3272e-01,  1.2194e+00],\n",
       "         [-1.1666e-01, -1.2571e-01, -2.3892e+00,  2.0524e-01],\n",
       "         [ 3.9256e-01, -2.6218e-01,  6.7841e-01,  1.6214e+00]],\n",
       "\n",
       "        [[ 3.0701e-01,  9.8639e-01,  1.3318e+00, -5.8268e-01],\n",
       "         [-5.3861e-01,  8.6189e-02, -7.3272e-01,  1.2194e+00],\n",
       "         [ 3.0701e-01,  9.8639e-01,  1.3318e+00, -5.8268e-01],\n",
       "         [-5.3861e-01,  8.6189e-02, -7.3272e-01,  1.2194e+00],\n",
       "         [-1.1666e-01, -1.2571e-01, -2.3892e+00,  2.0524e-01]],\n",
       "\n",
       "        [[ 3.9256e-01, -2.6218e-01,  6.7841e-01,  1.6214e+00],\n",
       "         [ 3.0701e-01,  9.8639e-01,  1.3318e+00, -5.8268e-01],\n",
       "         [-5.3861e-01,  8.6189e-02, -7.3272e-01,  1.2194e+00],\n",
       "         [ 7.5772e-01,  1.4073e+00,  4.3897e-01, -6.8380e-01],\n",
       "         [-4.2919e-01, -9.5861e-01, -4.1887e-02, -1.4541e+00]],\n",
       "\n",
       "        [[ 7.5772e-01,  1.4073e+00,  4.3897e-01, -6.8380e-01],\n",
       "         [-4.2919e-01, -9.5861e-01, -4.1887e-02, -1.4541e+00],\n",
       "         [ 7.5772e-01,  1.4073e+00,  4.3897e-01, -6.8380e-01],\n",
       "         [-4.2919e-01, -9.5861e-01, -4.1887e-02, -1.4541e+00],\n",
       "         [ 7.5772e-01,  1.4073e+00,  4.3897e-01, -6.8380e-01]],\n",
       "\n",
       "        [[-4.2919e-01, -9.5861e-01, -4.1887e-02, -1.4541e+00],\n",
       "         [ 7.5772e-01,  1.4073e+00,  4.3897e-01, -6.8380e-01],\n",
       "         [-4.2919e-01, -9.5861e-01, -4.1887e-02, -1.4541e+00],\n",
       "         [ 7.5772e-01,  1.4073e+00,  4.3897e-01, -6.8380e-01],\n",
       "         [-4.2919e-01, -9.5861e-01, -4.1887e-02, -1.4541e+00]],\n",
       "\n",
       "        [[ 7.5772e-01,  1.4073e+00,  4.3897e-01, -6.8380e-01],\n",
       "         [-4.2919e-01, -9.5861e-01, -4.1887e-02, -1.4541e+00],\n",
       "         [ 7.5772e-01,  1.4073e+00,  4.3897e-01, -6.8380e-01],\n",
       "         [-4.2919e-01, -9.5861e-01, -4.1887e-02, -1.4541e+00],\n",
       "         [ 7.5772e-01,  1.4073e+00,  4.3897e-01, -6.8380e-01]]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가중치 차원 변형 방법\n",
    "para.new(33, 5, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가중치 초기화 방법\n",
    "para.new(32, 5).zero_()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
