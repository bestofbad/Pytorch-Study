{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. IMDB Movie Review Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu와 cuda 중 다음 기기로 학습함: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2d81b2056d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchtext import data, datasets\n",
    "import random\n",
    "from torchtext.data import TabularDataset\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(\"cpu와 cuda 중 다음 기기로 학습함:\", DEVICE)\n",
    "\n",
    "SEED = 5\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-1. Review Data 수집 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('IMDb_Reviews.csv', <http.client.HTTPMessage at 0x2d818d6d2c8>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/LawrenceDuan/IMDb-Review-Analysis/master/IMDb_Reviews.csv\", filename=\"IMDb_Reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My family and I normally do not watch local mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Believe it or not, this was at one time the wo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>After some internet surfing, I found the \"Home...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One of the most unheralded great works of anim...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It was the Sixties, and anyone with long hair ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  My family and I normally do not watch local mo...          1\n",
       "1  Believe it or not, this was at one time the wo...          0\n",
       "2  After some internet surfing, I found the \"Home...          0\n",
       "3  One of the most unheralded great works of anim...          1\n",
       "4  It was the Sixties, and anyone with long hair ...          0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('IMDb_Reviews.csv', encoding='latin1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 개수 : 50000\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플의 개수 : {}'.format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My family and I normally do not watch local mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Believe it or not, this was at one time the wo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>After some internet surfing, I found the \"Home...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One of the most unheralded great works of anim...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It was the Sixties, and anyone with long hair ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  My family and I normally do not watch local mo...          1\n",
       "1  Believe it or not, this was at one time the wo...          0\n",
       "2  After some internet surfing, I found the \"Home...          0\n",
       "3  One of the most unheralded great works of anim...          1\n",
       "4  It was the Sixties, and anyone with long hair ...          0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PC 사양에 비해 Sample 수가 많으므로, 200개로 줄여 새로운 파일을 만든 후 사용\n",
    "df = pd.read_csv('IMDb_Reviews_200.csv', encoding='latin1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 개수 : 200\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플의 개수 : {}'.format(len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련 데이터, 평가 데이터, 테스트 데이터로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[:150]\n",
    "test_df = df[150:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train_data.csv\", index=False)\n",
    "test_df.to_csv(\"test_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-2. Field 정의 및 Dataset 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(sequential=True,lower=True, batch_first=True)\n",
    "LABEL = data.Field(sequential=False, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = TabularDataset.splits(\n",
    "        path='.', train='train_data.csv', test='test_data.csv', format='csv',\n",
    "        fields=[('text', TEXT), ('label', LABEL)], skip_header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset sample 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플의 개수 : 150\n",
      "테스트 샘플의 개수 : 50\n"
     ]
    }
   ],
   "source": [
    "print('훈련 샘플의 개수 : {}'.format(len(trainset)))\n",
    "print('테스트 샘플의 개수 : {}'.format(len(testset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-3. Vocabulary set 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(trainset, min_freq=5) # 단어 집합 생성\n",
    "LABEL.build_vocab(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 847\n"
     ]
    }
   ],
   "source": [
    "n_vocab = len(TEXT.vocab)\n",
    "print('단어 집합의 크기 : {}'.format(n_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터와 평가 데이터 분리\n",
    "trainset_2, valset = trainset.split(split_ratio=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플의 개수 : 112\n",
      "평가 샘플의 개수 : 38\n"
     ]
    }
   ],
   "source": [
    "print('훈련 샘플의 개수 : {}'.format(len(trainset_2)))\n",
    "print('평가 샘플의 개수 : {}'.format(len(valset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-4. Data loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5\n",
    "\n",
    "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
    "        (trainset_2, valset, testset), batch_size=BATCH_SIZE,\n",
    "        shuffle=True, repeat=False, sort=False) \n",
    "        # sort=False를 하지 않으면   '<' not supported ... Error 발생할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 미니 배치의 개수 : 23\n",
      "검증 데이터의 미니 배치의 개수 : 8\n",
      "테스트 데이터의 미니 배치의 개수 : 10\n"
     ]
    }
   ],
   "source": [
    "print('훈련 데이터의 미니 배치의 개수 : {}'.format(len(train_iter)))\n",
    "print('검증 데이터의 미니 배치의 개수 : {}'.format(len(val_iter)))\n",
    "print('테스트 데이터의 미니 배치의 개수 : {}'.format(len(test_iter)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 샘플의 개수 재확인 : 112\n",
      "검증 데이터의 샘플의 개수 재확인 : 38\n",
      "테스트 데이터의 샘플의 개수 재확인 : 50\n"
     ]
    }
   ],
   "source": [
    "print('훈련 데이터의 샘플의 개수 재확인 : {}'.format(len(train_iter.dataset)))\n",
    "print('검증 데이터의 샘플의 개수 재확인 : {}'.format(len(val_iter.dataset)))\n",
    "print('테스트 데이터의 샘플의 개수 재확인 : {}'.format(len(test_iter.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-5. Designing Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myModel(nn.Module):\n",
    "    def __init__(self, n_layers, hidden_size, n_vocab, embed_dim,\n",
    "                 n_classes, dropout_p):\n",
    "        super(myModel, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embed = nn.Embedding(n_vocab, embed_dim)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.gru = nn.GRU(embed_dim, self.hidden_size,num_layers=self.n_layers,\n",
    "                          batch_first=True)\n",
    "        self.out = nn.Linear(self.hidden_size, n_classes)\n",
    "                    # n_classes  : 분류되어야 할 결과 수 (긍정 or 부정)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)                             # (batch 크기 x 문장 단어 크기 x embedding 크기)\n",
    "        h_0 = self._init_state(batch_size=x.size(0))  # first hidden state 초기화, x.size(0)는 batch 크기\n",
    "        x_out, _ = self.gru(x, h_0)                   # x_out 벡터 : (batch 크기 x 문장 길이 x 은닉층 크기)\n",
    "        h_t = x_out[:,-1,:]                           # 마지막 hidden state 선택\n",
    "        h_t = self.dropout(h_t)\n",
    "        out = self.out(h_t)                           # (batch 크기 x 분류 갯수)\n",
    "        return out\n",
    "\n",
    "    def _init_state(self, batch_size=1):               # hidden state 초기화 정의\n",
    "        weight = next(self.parameters()).data          # myModel의 가중치 값들을 출력\n",
    "        return weight.new(self.n_layers, batch_size,  # 가중치 전체 갯수를 유지하면서, \n",
    "                          self.hidden_size).zero_()     # hidden state 차원으로 즉, \n",
    "                                                       # (층 크기 x batch 크기 x 은닉층 크기)로 바꾸고,\n",
    "                                                       # 모두 초기화 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 (n_vocab) : 847\n"
     ]
    }
   ],
   "source": [
    "n_layers = 2        # 은닉층 수\n",
    "hidden_size = 128     # 은닉층 크기\n",
    "print('단어 집합의 크기 (n_vocab) : {}'.format(n_vocab))\n",
    "embed_dim= 64      # 임베딩 된 차원의 크기 및 RNN 층 입력 차원의 크기\n",
    "n_classes = 2       # 분류되어야 할 결과 수 (긍정 or 부정)\n",
    "dropout_p = 0.3\n",
    "lr = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = myModel(n_layers, hidden_size, n_vocab, embed_dim, n_classes, dropout_p).to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-6. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Code의 간결함을 위해 Model 훈련과 검증을 함수로 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_iter):\n",
    "    for b, batch in enumerate(train_iter):\n",
    "        x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n",
    "        y.data.sub_(1)            # lable 값 0 또는 1로 조정\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = F.cross_entropy(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_iter):\n",
    "    corrects, total_loss = 0, 0\n",
    "    for batch in val_iter:\n",
    "        x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n",
    "        y.data.sub_(1)\n",
    "        output = model(x)\n",
    "        loss = F.cross_entropy(output, y, reduction='sum')\n",
    "        total_loss += loss.item()                   # loss 누적 값\n",
    "        corrects += (output.max(1)[1].view(y.size()).data == y.data).sum()   # 정답 맞춘 총횟수\n",
    "    size = len(val_iter.dataset)\n",
    "    avg_loss = total_loss / size\n",
    "    avg_accuracy = 100.0 * corrects / size\n",
    "    return avg_loss, avg_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1] val loss :  0.69 | val accuracy : 55.26\n",
      "[Epoch: 2] val loss :  0.71 | val accuracy : 44.74\n",
      "[Epoch: 3] val loss :  0.80 | val accuracy : 42.11\n",
      "[Epoch: 4] val loss :  0.69 | val accuracy : 57.89\n",
      "[Epoch: 5] val loss :  0.68 | val accuracy : 47.37\n",
      "[Epoch: 6] val loss :  0.71 | val accuracy : 52.63\n",
      "[Epoch: 7] val loss :  0.70 | val accuracy : 44.74\n",
      "[Epoch: 8] val loss :  0.69 | val accuracy : 52.63\n",
      "[Epoch: 9] val loss :  0.74 | val accuracy : 44.74\n",
      "[Epoch: 10] val loss :  0.71 | val accuracy : 60.53\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "best_val_loss = None\n",
    "for e in range(1, EPOCHS+1):\n",
    "    train(model, optimizer, train_iter)\n",
    "    val_loss, val_accuracy = evaluate(model, val_iter)\n",
    "\n",
    "    print(\"[Epoch: %d] val loss : %5.2f | val accuracy : %5.2f\" % (e, val_loss, val_accuracy))\n",
    "\n",
    "    # 검증 오차가 가장 적은 최적의 모델을 저장\n",
    "    if not best_val_loss or val_loss < best_val_loss:\n",
    "        if not os.path.isdir(\"snapshot\"):\n",
    "            os.makedirs(\"snapshot\")\n",
    "        torch.save(model.state_dict(), './snapshot/txtclassification.pt')\n",
    "        best_val_loss = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-7. 최적 가중치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 오차:  0.72 | 테스트 정확도: 38.00\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./snapshot/txtclassification.pt'))    # 저장된 최적 모델 꺼내기\n",
    "test_loss, test_acc = evaluate(model, test_iter)                        # 평가 진행\n",
    "print('테스트 오차: %5.2f | 테스트 정확도: %5.2f' % (test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Reference  : https://wikidocs.net/60691\n",
    "\n",
    "    GRU 관련 : https://blog.floydhub.com/gru-with-pytorch/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
